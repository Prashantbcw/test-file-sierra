<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<dict>
    <entry key="blockstrategy">
        <dict>
            <entry key="maxblocktime">
                <int>30000</int>
            </entry>
            <entry key="name">
                <string>net.postchain.base.BaseBlockBuildingStrategy</string>
            </entry>
        </dict>
    </entry>
    <entry key="config_consensus_strategy">
        <string>HEADER_HASH</string>
    </entry>
    <entry key="configurationfactory">
        <string>net.postchain.gtx.GTXBlockchainConfigurationFactory</string>
    </entry>
    <entry key="gtx">
        <dict>
            <entry key="modules">
                <array>
                    <string>net.postchain.rell.module.RellPostchainModuleFactory</string>
                    <string>net.postchain.gtx.StandardOpsGTXModule</string>
                    <string>net.postchain.d1.icmf.IcmfReceiverGTXModule</string>
                </array>
            </entry>
            <entry key="rell">
                <dict>
                    <entry key="moduleArgs">
                        <dict>
                            <entry key="auth_service">
                                <dict>
                                    <entry key="include_system_cluster">
                                        <int>1</int>
                                    </entry>
                                    <entry key="pubkey">
                                        <bytea>02B6F2967CF9AFC4D289EF475A2C2DDEC9EAB79AC60C1C99683E3134074619E635</bytea>
                                    </entry>
                                </dict>
                            </entry>
                            <entry key="common">
                                <dict>
                                    <entry key="allow_blockchain_dependencies">
                                        <int>1</int>
                                    </entry>
                                </dict>
                            </entry>
                            <entry key="common.init">
                                <dict>
                                    <entry key="genesis_node">
                                        <array>
                                            <string>037B88FA53A9009A439CC2EB13F0E31D5F364390B3742B7AD091C03216EBF43948</string>
                                            <string>appnet.chromia.dev</string>
                                            <int>9870</int>
                                            <string>https://appnet.chromia.dev:7740</string>
                                        </array>
                                    </entry>
                                    <entry key="initial_provider">
                                        <string>02EC8AC937846DF24C939801BB0155EE0C1B7CBE4993ACD7669B8962BE1033A4A9</string>
                                    </entry>
                                </dict>
                            </entry>
                            <entry key="housekeeping">
                                <dict>
                                    <entry key="max_empty_container_time">
                                        <int>172800000</int>
                                    </entry>
                                </dict>
                            </entry>
                        </dict>
                    </entry>
                    <entry key="modules">
                        <array>
                            <string>management_chain_testnet</string>
                        </array>
                    </entry>
                    <entry key="sources">
                        <dict>
                            <entry key="auth_service/auth_service.rell">
                                <string>
namespace auth_service {

    operation create_provider(pubkey, name?, url: text?) {
        require_module_auth();
        require_pubkey(pubkey);
        require(not(exists(provider @? { pubkey })), "Provider with pubkey %s already exists".format(pubkey));
        register_and_enable_provider(provider_info(pubkey, name = name ?: "", url = url ?: ""), provider_tier.COMMUNITY_NODE_PROVIDER, null, null, true);
    }

    operation create_container(pubkey, cluster_name: text?) {
        require_module_auth();
        require_pubkey(pubkey);
        require(empty((voter_set_member, container) @? {
            container.deployer == voter_set_member.voter_set,
            voter_set_member.provider.pubkey == pubkey
        }), "Only one container per provider can be created");
        if (cluster_name != null) {
            val cluster = require_cluster(cluster_name);
            create_container_in_cluster(pubkey, cluster);
            return;
        }

        val clusters = if (chain_context.args.include_system_cluster) cluster @* {} else cluster @* { cluster.name != clusters.system };
        for (cluster in clusters) {
            val available_container_units = get_available_container_units(cluster);
            if (available_container_units &gt; 0) {
                create_container_in_cluster(pubkey, cluster);
                return;
            }
        }
        require(false, "No available clusters exist");
    }

    function create_container_in_cluster(pubkey, cluster) {
        val name = [cluster.to_gtv(), pubkey.to_gtv(), op_context.transaction.tx_rid.to_gtv()].hash().to_hex();
        if (not(exists(provider @? { pubkey }))) {
            register_and_enable_provider(
                provider_info(pubkey),
                provider_tier.COMMUNITY_NODE_PROVIDER,
                null,
                null,
                enabled_by_default = true
            );
        }
        create_container_impl(provider @ { pubkey }, name, cluster, 1, [pubkey], standard_container_defaults.container_units, standard_container_defaults.max_blockchains);
    }

    query get_licenses(pubkey) : list&lt;text&gt; { 
        return (c: container, vsm: voter_set_member) @* { 
            c.deployer == vsm.voter_set,
            vsm.provider.pubkey == pubkey
        }.name;
    }

}
</string>
                            </entry>
                            <entry key="auth_service/module.rell">
                                <string>module;

import model.*;
import common.*;
import proposal.*;

/**
* This module creates an operation that must be signed by this pubkey.
*/
struct module_args {
    pubkey;
    include_system_cluster: boolean;
}

function require_module_auth() = require(op_context.is_signer(chain_context.args.pubkey), "This operation must be signed by " + chain_context.args.pubkey);
</string>
                            </entry>
                            <entry key="cm_api/module.rell">
                                <string>module;

import common.*;
import model.*;

/*
 * Cluster Management api used by postchain to get information about cluster anchoring chains
*/

struct cm_peer_info {
    pubkey: pubkey;
    api_url: text;
}

struct cm_cluster_info {
    name;
    anchoring_chain: byte_array;
    peers: list&lt;cm_peer_info&gt;;
}

query cm_get_cluster_info(name): cm_cluster_info {
    val cluster = require_cluster(name);
    val cac = require(cluster_anchoring_chain @? { cluster }, "Cluster anchoring chain not found for cluster " + name);
    val cluster_peer = cluster_node @* {
        cluster_node.cluster == cluster,
        cluster.name == name
    } (
        peer = .node.pubkey,
        peer_api_url = .node.api_url
    ); 
    val peers = list&lt;cm_peer_info&gt;();
    for (cp in cluster_peer) {
        peers.add(cm_peer_info(pubkey = cp.peer, api_url = cp.peer_api_url));
    }
    return cm_cluster_info(
        name = cluster.name,
        anchoring_chain = cac.blockchain.rid,
        peers = peers
    );
}

query cm_get_cluster_names(): list&lt;text&gt; {
    return cluster @* { .operational == true } ( .name );
}

query cm_get_cluster_blockchains(name): list&lt;byte_array&gt; {
    return (container_blockchain) @* { .container.cluster.name == name } ( .blockchain.rid );
}

// Returns signers of blockchain at specific height
// NB: doesn't take into account pending configurations
query cm_get_peer_info(brid: byte_array, height: integer): set&lt;pubkey&gt; {
    val bc = require_blockchain(brid, include_removed=true);
    return set&lt;pubkey&gt;.from_gtv(
        get_signers_for_configuration(bc, height)
    );
}

query cm_get_blockchain_cluster(brid: byte_array): text {
    val bc = require_blockchain(brid, include_removed=true);    
    return container_blockchain @ { bc } ( .container.cluster.name );
}

query cm_get_blockchain_api_urls(blockchain_rid: byte_array) {
    return (blockchain, container_blockchain, cluster_node) @*
    {
        blockchain.rid == blockchain_rid,
        container_blockchain.blockchain.rid == blockchain.rid,
        container_blockchain.container.cluster == cluster_node.cluster
    } (
        cluster_node.node.api_url
    );
}

query cm_get_cluster_anchoring_chains(): list&lt;byte_array&gt; {
    return cluster_anchoring_chain @* {} ( .blockchain.rid );
}

query cm_get_system_anchoring_chain(): byte_array? {
    if (system_anchoring_chain.rid.empty()) return null;

    return system_anchoring_chain.rid;
}

query cm_get_system_chains(): list&lt;byte_array&gt; {
    return blockchain @* { .system }.rid;
}</string>
                            </entry>
                            <entry key="common/anchoring_cluster.rell">
                                <string>
function set_cluster_anchoring_config(config: byte_array) {
    map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config)); // Validate that config is a map
    cluster_anchoring_config.raw_config = config;
}

@extend(after_cluster_operational) function activate_cluster_anchoring_chain(cluster) {
    val config_map = map&lt;text,gtv&gt;.from_gtv(gtv.from_bytes(cluster_anchoring_config.raw_config));

    // feature toggle
    if (not(exists(cluster_anchoring_chain @? { cluster } (.blockchain))) and config_map.size() &gt; 0) {
        require(empty(cluster_anchoring_chain @? { cluster }), "Anchoring chain already exists for cluster " + cluster.name);

        val system_container = container @ { .name == system_container_name(cluster.name), cluster };
        val cluster_signers = cluster_node @* { cluster } (@sort .node.pubkey);
        val blockchain_name = blockchains.cluster_anchoring_prefix + cluster.name;
        config_map["cluster"] = cluster.name.to_gtv();
        val unique_config = config_map.to_gtv_pretty();

        val blockchain = add_blockchain(unique_config.to_bytes(), cluster_signers, blockchain_name, system_container, system = true, state = blockchain_state.RUNNING);
        
        create cluster_anchoring_chain(blockchain, cluster);

        if (cluster.name != clusters.system) {
            // Add replication of this chain to all system nodes
            val system_cluster_nodes = cluster_node @* { .cluster.name == clusters.system  } ( .node );
            for (node in system_cluster_nodes) {
                create blockchain_replica_node(blockchain, node);
            }
        }
    }
}

@extend(before_system_container_removal) function remove_cluster_anchoring_chain(cluster) {
    val anchor = cluster_anchoring_chain @? { cluster } (.blockchain);
    if (exists(anchor)) {
        anchor.state = blockchain_state.REMOVED;
        delete container_blockchain @* { anchor };
        delete cluster_anchoring_chain @ { anchor };
        delete blockchain_replica_node @* { anchor };
    }
}

@extend(after_node_added_to_cluster) function replicate_cluster_anchor_chain_on_system_node(cluster, node) {
    if (cluster.name == clusters.system) {
        val cluster_anchoring_chains = cluster_anchoring_chain @* { .cluster.name != clusters.system } ( .blockchain );
        for (blockchain in cluster_anchoring_chains) {
            if (not(exists(blockchain_replica_node @? { blockchain, node }))) {
                create blockchain_replica_node(blockchain, node);
            }
        }
    }
}
</string>
                            </entry>
                            <entry key="common/anchoring_system.rell">
                                <string>import common.*;

@extend(after_node_added) function replicate_system_anchoring_chain_on_node(node) {
    if (system_anchoring_chain.rid.empty()) return;

    if (not(exists(cluster_node @? { node, .cluster.name == clusters.system }))) {
        val system_anchoring_blockchain = blockchain @ { .rid == system_anchoring_chain.rid };

        if (not(exists(blockchain_replica_node @? { system_anchoring_blockchain, node }))) {
            create blockchain_replica_node(system_anchoring_blockchain, node);
        }
    }
}
</string>
                            </entry>
                            <entry key="common/blockchain.rell">
                                <string>function allow_blockchain_dependencies() = chain_context.args.allow_blockchain_dependencies;

function add_blockchain(
    base_configuration: byte_array,
    signers: list&lt;pubkey&gt;,
    name: text, 
    container,
    system: boolean = false,
    state: blockchain_state = blockchain_state.RUNNING
): blockchain {
    val blockchain_rid = calculate_configuration_hash(base_configuration, signers);
    val blockchain = create blockchain(blockchain_rid, name, system, state);
    create blockchain_configuration(blockchain, 0, base_configuration);
    create blockchain_configuration_signers(blockchain, 0, signers.to_gtv().to_bytes());
    create container_blockchain(container, blockchain);
    add_dependencies(base_configuration, blockchain_rid, 0);
    return blockchain;
}

function add_dependencies(raw_config: byte_array, brid: byte_array, height: integer) {
    val config_map = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(raw_config));
    if (config_map.contains("dependencies")) {
        require(allow_blockchain_dependencies(), "Blockchain dependencies are not allowed");
        val dependencies = list&lt;(text, byte_array)&gt;.from_gtv(config_map["dependencies"]);   // Returns e.g.  [brid0, brid22, ..]
        val blockchain = blockchain @ { brid };
        val container = container_blockchain @ { blockchain }.container;
        for ((_, dependency_brid) in dependencies) {
            val dependency_blockchain = blockchain @? { dependency_brid };
            if (exists(dependency_blockchain)) {
                require(brid != dependency_brid);
                require(container_blockchain @ { dependency_blockchain }.container == container,
                    "Blockchain dependencies are only allowed within the same container");
                create blockchain_dependency(
                    me = blockchain,
                    dependent_on = dependency_blockchain,
                    height = height);
            }
        }
    }
}

function require_no_dependencies_on_me(blockchain) {
    require (empty(blockchain_dependency @* { .dependent_on == blockchain}));
}

function get_blockchain_signer_nodes(blockchain: blockchain): list&lt;node&gt; {
    return (cluster_node, container_blockchain) @* {
        container_blockchain.blockchain == blockchain,
        cluster_node.cluster == container_blockchain.container.cluster
    } ( .node );
}

function get_signers_for_configuration(blockchain, height: integer): gtv {
    val raw_signers = blockchain_configuration_signers @ { blockchain, .height &lt;= height }
        (@omit @sort_desc .height, .signers) limit 1;
    return gtv.from_bytes(raw_signers);
}

function isAlive(blockchain): boolean {
    return blockchain.state == blockchain_state.RUNNING or blockchain.state == blockchain_state.PAUSED;
}

function calculate_configuration_hash(base_config: byte_array, signers: list&lt;pubkey&gt;): byte_array {
    val full_config = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(base_config));
    full_config["signers"] = signers.to_gtv();
    return full_config.to_gtv().hash();    
}

function get_blockchain_configuration(blockchain_rid: byte_array, height: integer):
    (base_config: byte_array, signers: list&lt;pubkey&gt;, config_hash: byte_array)?
{
    val bc = require_blockchain(blockchain_rid, include_removed = true);
    // Find configuration height -- the latest height up to given height.
    // If conf_h exist, so does signer_h, thus no need to check both.
    val base_config = blockchain_configuration @? { bc, .height &lt;= height } (@omit @sort_desc .height, .data) limit 1;
    if (base_config != null) {
        // Checking that signers.size() is non-zero is done when population blockchain_configuration_signers.
        val signers = require(blockchain_configuration_signers @? { bc, .height &lt;= height }
            (@omit @sort_desc .height, list&lt;pubkey&gt;.from_gtv(gtv.from_bytes(.signers))) limit 1,
            "No signers configuration for blockchain %s for height %d".format(blockchain_rid, height)
        );
        return (
            base_config = base_config,
            signers = signers,
            config_hash = calculate_configuration_hash(base_config, signers)
        );
    } else {
        return null;
    }
}

@extendable function before_delete_blockchain(blockchain) {}
</string>
                            </entry>
                            <entry key="common/cluster.rell">
                                <string>function create_cluster_impl(
        me: provider, name, governor: voter_set, providers: list&lt;pubkey&gt;,
        cluster_units: integer = standard_cluster_defaults.cluster_units
    ) {
    require(empty(cluster @* { name }), "Cluster with name %s already exists".format(name));
    require(cluster_units &gt; 0, "Cluster must have at least 1 cluster unit");
    val c = create cluster(name, governor, false, cluster_units);

    for (p_key in providers) {
        val provider = require_provider(p_key);
        require_node_access(provider);
        create cluster_provider(c, provider);
    }

    create_system_container(
        me,
        system_container_name(c.name),
        cluster = c,
        voter_set = governor
    );

    after_cluster_creation(me, c);
    return c;
}

function require_cluster_quotas(cluster, wanted_container_units: integer) {
    if (wanted_container_units &lt; 1) return;
    val available_container_units = get_available_container_units(cluster);
    require(wanted_container_units &lt;= available_container_units,
        "Can not propose container, cluster %s has %d available container units but wanted %d".format(cluster.name, available_container_units, wanted_container_units));
}

function get_available_container_units(cluster): integer {
    val max_container_units = get_max_container_units_for_cluster(cluster);
    val used_container_units = get_used_container_units(cluster);
    return max_container_units - used_container_units;
}

function get_max_container_units_for_cluster(cluster): integer {
    return standard_cluster_unit.container_units * cluster.cluster_units;
}

function get_used_container_units(cluster): integer {
    return container_resource_limit @ {
        .container.cluster == cluster,
        container_resource_limit_type.container_units
    } (@sum .value);
}

function get_minimum_cluster_units_for_current_container_units(cluster): integer {
    val currently_used_container_units = get_used_container_units(cluster);
    return currently_used_container_units / standard_cluster_unit.container_units + 1;
}

function _add_replica_node_to_cluster_internal(cluster, node) {
    require_cluster_units_for_node(cluster, node);
    create cluster_replica_node(cluster, node);
}

function _remove_replica_node_from_cluster_internal(node) {
    delete cluster_replica_node @* { node };
}

/**
 * When all providers have provided a node each, cluster goes operational and
 * stays operational even if a new provider is added to the cluster or
 * a provider disables its node (if it is not the last node of the cluster).
 */
function check_operational(cl: cluster) {
    val providers = cluster_provider @* { cl }.provider;
    val nodes = cluster_node @* { cl }.node;
    if (nodes.size() == providers.size()) {
        update cluster @ { cl.name } (.operational = true);
        after_cluster_operational(cl);
    }
}

/**
 * If a provider is part of that cluster, and if provider do not already have a node in this cluster,
 * add node as block signer to this cluster. blockchain_configuration_signers update is included.
 */
function add_node_to_cluster_internal(provider, node, cluster) {
    if (exists(cluster_node @? { cluster, node })) {
        log("Node %s already is part of cluster %s".format(node.pubkey, cluster.name));
        return;
    }

    if (exists(cluster_provider @* { cluster, provider })) {
        val provider_cluster_nodes = cluster_node @* { cluster, .node in node @* { provider } };
        require(empty(provider_cluster_nodes), "A provider can only provide one node to each cluster");
        _remove_replica_node_from_cluster_internal(node);
        require_cluster_units_for_node(cluster, node);
        create cluster_node(cluster, node);
        update_configuration_signers(cluster, null);
        // check if cluster now is operational, if so update the flag:
        check_operational(cluster);
        log("blockchain configuration signers are updated");
        after_node_added_to_cluster(cluster, node);
    } else {
        log("Provider %s is not a member of cluster %s".format(provider.pubkey, cluster.name));
    }
}

// Use this to update signers after a change in cluster_node table.
function update_configuration_signers(cluster, excluded_node: node?) {
    val signers = cluster_node @* { cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(signers.size() &gt; 0);

    val bcs = container_blockchain @* { .container.cluster == cluster } .blockchain;
    for (blockchain in bcs) {
        val is_chain0 = blockchain.rid == chain_context.blockchain_rid;
        if (is_chain0) {
            update_configuration_signers_chain0(blockchain, signers);
        } else {
            update_configuration_signers_regular(blockchain, signers, excluded_node?.pubkey);
        }
    }
}

function update_configuration_signers_chain0(blockchain, signers: list&lt;pubkey&gt;) {
    val height = op_context.block_height + 1; // NB: compute_blockchain_info_list()/get_cluster_node_blockchains() relies on this
    log("Signers update for chain0 at height %d: %s".format(height, signers));

    // make a base_config at `height` unique
    if (empty(blockchain_configuration @? { blockchain, height })) {
        val base_config = blockchain_configuration @? { blockchain, .height &lt; height } (@omit @sort_desc .height, .data) limit 1;
        val unique_base_config = make_config_unique(base_config!!);
        create blockchain_configuration(blockchain, height, unique_base_config);
        add_dependencies(unique_base_config, blockchain.rid, height);
    }

    // signers
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function update_configuration_signers_regular(blockchain, signers: list&lt;pubkey&gt;, excluded_signer: pubkey?) {
    val last_signers_config = blockchain_configuration_signers @? { blockchain } (@sort_desc .height, .signers) limit 1;

    if (last_signers_config == null) {
        // No initial signers config found, add new config as initial
        create blockchain_configuration_signers(blockchain, 0, signers.to_gtv().to_bytes());
        return;
    }

    val last_pending_config = pending_blockchain_configuration @? { blockchain } (@sort_desc @omit .minimum_height, $) limit 1;
    val (minimum_height, base_config, last_signers) = if (last_pending_config != null) (
        last_signers_config.height.max(last_pending_config.minimum_height) + 1,
        last_pending_config.base_config,
        last_pending_config.signers
    ) else (
        last_signers_config.height + 1,
        blockchain_configuration @ { blockchain } (@omit @sort_desc .height, .data) limit 1,
        last_signers_config.signers
    );

    if (signers.to_gtv().to_bytes() == last_signers) {
        log("Signers update for chain %s not necessary, already %s".format(blockchain.rid, signers));
        return;
    }

    log("Signers update for chain %s at minimum height %d: %s".format(blockchain.rid, minimum_height, signers));
    val unique_base_config = make_config_unique(base_config);
    val config_hash = calculate_configuration_hash(unique_base_config, signers);
    create pending_blockchain_configuration(
        blockchain,
        minimum_height,
        config_hash = config_hash,
        base_config = unique_base_config,
        signers = signers.to_gtv().to_bytes()
    );

    if (excluded_signer != null) {
        create signer_excluded_from_pending_configuration(
            blockchain,
            config_hash = config_hash,
            pubkey = excluded_signer
        );
    }
}

function require_cluster_available_for_removal(cluster) {
    require(cluster.name != clusters.system, "System cluster can't be deleted");
    require(
        empty(container @* { cluster, .system == false }),
        "Cluster %s is not empty and can't be deleted. Delete containers first".format(cluster.name)
    );
}

function get_cluster_for_blockchain(blockchain_rid: byte_array): cluster {
    return (container_blockchain, blockchain) @ { blockchain.rid == blockchain_rid, blockchain == container_blockchain.blockchain }
                 ( container_blockchain.container.cluster );
}

function remove_cluster_impl(cluster) {
    before_cluster_removal(cluster);
    delete cluster_node @* { cluster };
    delete cluster_replica_node @* { cluster };
    delete cluster_provider @* { cluster };
    delete cluster;
}

@extendable function before_cluster_removal(cluster) {}

@extendable function after_cluster_creation(provider, cluster) {}

@extendable function after_cluster_operational(cluster) {}

@extendable function after_node_added_to_cluster(cluster, node) {}
</string>
                            </entry>
                            <entry key="common/configuration_failed.rell">
                                <string>@extend(receive_icmf_message) function receive_configuration_failed(sender: byte_array, topic: text, body: gtv) {
    if (topic != configuration_failed_topic) return;

    val message = configuration_failed.from_gtv(body);

    if (message.blockchain_rid == chain_context.blockchain_rid) {
        log("Received failed configuration from chain %s for chain0 at height %d to %s, ignoring"
            .format(sender, message.height, message.config_hash));
        return;
    }
    val bc = blockchain @? { message.blockchain_rid };
    if (bc == null) {
        log("Unknown blockchain " + message.blockchain_rid);
        return;
    }

    val cluster = get_cluster_for_blockchain(message.blockchain_rid);
    val anchoring_chain = cluster_anchoring_chain @? { cluster } (.blockchain);
    if (anchoring_chain == null) {
        log("No anchoring chain for cluster %s".format(cluster.name));
        return;
    }
    if (sender != anchoring_chain.rid and sender != system_anchoring_chain.rid) {
        log("Received failed configuration from chain %s, which is not anchor chain for cluster %s".format(sender, cluster.name));
        return;
    }

    val pending_configuration = pending_blockchain_configuration @?
        { bc, .config_hash == message.config_hash, .minimum_height &lt;= message.height };
    if (pending_configuration == null) {
        log("Configuration with hash %s and minimum_height&lt;=%d not found for chain %s".format(message.config_hash, message.height, message.blockchain_rid));
        return;
    }

    log("Deleting failed pending configuration with hash %s for chain %s".format(message.config_hash, message.blockchain_rid));

    create faulty_blockchain_configuration(
        blockchain = bc,
        config_hash = message.config_hash,
        reported_at_height = message.height
    );

    // Moving excluded signers of failed pending config back to cluster signers.
    val cluster_signers = cluster_node @* { cluster } ( .node.pubkey );
    val excluded_signers = signer_excluded_from_pending_configuration @* {
        bc, .config_hash == pending_configuration.config_hash, .pubkey not in cluster_signers
    } ( .pubkey );
    if (exists(excluded_signers)) {
        log("Pending config %s failed, removed signers will be re-added to the cluster %s".format(pending_configuration.config_hash, cluster.name));
        for (signer in excluded_signers) {
            create cluster_node(cluster, require_node(signer));
            log("cluster_node created: " + signer);
        }
    }
    delete signer_excluded_from_pending_configuration @* { bc, .config_hash == pending_configuration.config_hash };

    delete pending_configuration;
}
</string>
                            </entry>
                            <entry key="common/configuration_updated.rell">
                                <string>@extend(receive_icmf_message) function receive_configuration_updated(sender: byte_array, topic: text, body: gtv) {
    if (topic != configuration_updated_topic) return;

    val message = configuration_updated.from_gtv(body);

    if (message.blockchain_rid == chain_context.blockchain_rid) {
        log("Received updated configuration from chain %s for chain0 at height %d to %s, ignoring"
            .format(sender, message.height, message.config_hash));
        return;
    }
    val bc = blockchain @? { message.blockchain_rid };
    if (bc == null) {
        log("Unknown blockchain " + message.blockchain_rid);
        return;
    }

    val cluster = get_cluster_for_blockchain(message.blockchain_rid);
    val anchoring_chain = cluster_anchoring_chain @? { cluster } (.blockchain);
    if (anchoring_chain == null) {
        log("No anchoring chain for cluster %s".format(cluster.name));
        return;
    }
    if (sender != anchoring_chain.rid and sender != system_anchoring_chain.rid) {
        log("Received updated configuration from chain %s, which is not anchor chain for cluster %s".format(sender, cluster.name));
        return;
    }

    log("Received updated configuration from chain %s for chain %s at height %d to %s"
        .format(sender, message.blockchain_rid, message.height, message.config_hash));

    // foreign blockchain
    val foreign_blockchain = foreign_blockchain_import @? { .blockchain_rid == message.blockchain_rid, .up_to_height == message.height - 1 };
    if (exists(foreign_blockchain)) {
        log("Foreign blockchain import was finished at height %s".format(message.height - 1));
        delete foreign_blockchain;
        delete blockchain_configuration_options @* { .blockchain.rid == message.blockchain_rid };
        return;
    }

    val pending_configuration = pending_blockchain_configuration @?
        { bc, .config_hash == message.config_hash, .minimum_height &lt;= message.height };
    if (pending_configuration == null) {
        log("Configuration with hash %s and minimum_height&lt;=%d not found for chain %s".format(message.config_hash, message.height, message.blockchain_rid));
        return;
    }

    val pending_base_config = pending_configuration.base_config;
    val pending_signers = pending_configuration.signers;
    if (blockchain_configuration @? { bc, message.height } != null) {
        log("Configuration at height %d already exists for chain %s".format(message.height, message.blockchain_rid));
        return;
    }

    delete signer_excluded_from_pending_configuration @* { bc, .config_hash == pending_configuration.config_hash };
    delete pending_configuration;

    create blockchain_configuration(bc, message.height, pending_base_config);

    val bc_signers = blockchain_configuration_signers @? { bc, message.height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(bc, message.height, pending_signers);
    } else {
        bc_signers.signers = pending_signers;
    }

    add_dependencies(pending_base_config, bc.rid, message.height);
}
</string>
                            </entry>
                            <entry key="common/container.rell">
                                <string>function create_system_container(me: provider, name, cluster, voter_set): container {
    val c = create container(name, cluster, voter_set, me, system = true);
    create container_resource_limit(c, container_resource_limit_type.container_units, system_container_defaults.container_units);
    create container_resource_limit(c, container_resource_limit_type.max_blockchains, system_container_defaults.max_blockchains);
    return c;
}

function create_container_with_resource_limits(me: provider, name, cluster, voter_set, container_units: integer, max_blockchains: integer): container {
    require(container_units &gt; 0, "Container must have at least 1 container unit");
    require_cluster_quotas(cluster, container_units);
    val c = create container(name, cluster, voter_set, me);
    create container_resource_limit(c, container_resource_limit_type.container_units, container_units);
    create container_resource_limit(c, container_resource_limit_type.max_blockchains, max_blockchains);
    return c;
}

function remove_container_impl(container) {
    delete container_resource_limit @* { container };
    delete container;
}

@extendable function is_container_available_for_removal(container): text? {
    return when {
        container.system -&gt; "System container can't be deleted";
        exists(container_blockchain @* { container }) -&gt; "Container %s is not empty and can't be deleted. Delete blockchains first".format(container.name);
        else -&gt; null;
    };
}

function require_container_available_for_removal(container) {
    val objections = is_container_available_for_removal(container);
    require(empty(objections), objections!!);
}

@extend(before_cluster_removal) function remove_system_container(cluster) {
    before_system_container_removal(cluster);
    remove_container_impl(container @ { cluster, .system == true });
}

@extendable function before_system_container_removal(cluster) {}

function create_container_impl(me: provider, name, cluster, consensus_threshold: integer, deployers: list&lt;pubkey&gt;, container_units: integer, max_blockchains: integer) {
    require(consensus_threshold &gt;= -1 and consensus_threshold &lt;= deployers.size(), "Invalid threshold");

    val vs_name = "container_" + name + "_deployer";
    require(empty(voter_set @? { vs_name }), "Voter set named %s already exists".format(vs_name));
    val vs = create_voter_set_internal(vs_name, consensus_threshold, cluster.governance);
    for (deployer_key in deployers) {
        val deployer = require_provider(deployer_key);
        create voter_set_member(vs, deployer);
    }

    create_container_with_resource_limits(me, name, cluster, vs, container_units, max_blockchains);
}

function remove_container_and_voter_set(container) {
    if (empty(is_container_available_for_removal(container))) {
        val vs = container.deployer;
        remove_container_impl(container);
    }
}

function get_current_container_resource_limits(container_name: text): map&lt;container_resource_limit_type, integer&gt; {
    var limits_map = map&lt;container_resource_limit_type, integer&gt;();
    val cur_limits_list = container_resource_limit @* { .container.name == container_name };
    for (l in cur_limits_list) {
        limits_map[l.container_resource_limit_type] = l.value;
    }
    return limits_map;
}

function get_container_limit_or_default(container, type: container_resource_limit_type, default: integer): integer {
    return container_resource_limit @? { container, .container_resource_limit_type == type } (.value) ?: default;
}

function require_container_is_not_full(container) {
    val max_blockchains = container_resource_limit @ { container, container_resource_limit_type.max_blockchains } (.value);
    if (max_blockchains &gt; 0) {
        val container_dapps_count = container_blockchain @* { container } (@sum 1)[0];
        require(container_dapps_count &lt; max_blockchains, "Can't add blockchain, container %s is full".format(container.name));
    }
}
</string>
                            </entry>
                            <entry key="common/icmf_receiver.rell">
                                <string>operation __icmf_message(sender: byte_array, topic: text, body: gtv) {
    receive_icmf_message(sender, topic, body);
}

@extendable function receive_icmf_message(sender: byte_array, topic: text, body: gtv) {}
</string>
                            </entry>
                            <entry key="common/init.rell">
                                <string>module;

import ^.*;
import model.*;

struct module_args {
    initial_provider: pubkey;
    genesis_node: node_info; 
    // actions_per_day: integer = 100; consider adding this module arg
}

// This operation will check that provider table is empty and if so add the provider supplied as module argument. And
// enable this first system provider.
operation init(system_anchoring_config: byte_array?, cluster_anchoring_config: byte_array?) {
    require_pubkey(chain_context.args.initial_provider);

    val genesis_node = chain_context.args.genesis_node;
    require_pubkey(genesis_node.pubkey);

    if (system_anchoring_config != null) {
        require(cluster_anchoring_config, "System anchoring requires cluster anchoring");
    }

    initialize_module(
        chain_context.args.initial_provider,
        genesis_node,
        system_anchoring_config = system_anchoring_config ?: map&lt;text, gtv&gt;().to_gtv().to_bytes(),
        cluster_anchoring_config = cluster_anchoring_config ?: map&lt;text, gtv&gt;().to_gtv().to_bytes()
    );
    after_init();
}

@extendable function after_init() {}
</string>
                            </entry>
                            <entry key="common/module.rell">
                                <string>module;

import model.*;
import messaging.configuration_update_message.*;
import proposal.*;
import roles.*;

struct module_args {
    allow_blockchain_dependencies: boolean;
}

// Adds the initial provider as a system provider along with voter sets and clusters needed to start
function initialize_module(
    initial_provider: pubkey,
    genesis_node: node_info,
    system_anchoring_config: byte_array,
    cluster_anchoring_config: byte_array,
    majority_threshold: integer = 0,
    provider_quota_max_actions_per_day: integer = provider_quota_defaults.MAX_ACTIONS_PER_DAY,
    provider_quota_max_containers: integer = provider_quota_defaults.MAX_CONTAINERS
) {
    require(empty( provider @* {}));
    log("--------------------Initializing-Chain-0-----------------------");
    log("Creating provider quotas");
    _setup_provider_quotas(provider_quota_max_actions_per_day, provider_quota_max_containers);

    log("Creating SYSTEM voter set");
    create_voter_set_internal(voter_sets.system, 1);
    /**
     * System provider create a ‘system’ cluster which will include ‘system’ nodes and has a ‘system’ container
     * which will run the directory bc.
     */
    log("Creating SYSTEM_P voter set");
    val system_voter_set = create_voter_set_internal(voter_sets.system_p, majority_threshold);

    log("Creating initial provider with pubkey: " + initial_provider);
    register_and_enable_provider(
        provider_info(initial_provider),
        provider_tier.NODE_PROVIDER,
        cluster = null,
        voter_set = null,
        enabled_by_default = true
    );
    val provider = provider @ { initial_provider };

    log("Creating system cluster with SYSTEM_P as governor");
    set_cluster_anchoring_config(cluster_anchoring_config);
    val system_cluster = create_cluster_impl(
        provider,
        clusters.system,
        governor = system_voter_set,
        providers = list&lt;pubkey&gt;()
       );

    enroll.system(provider);

    val system_container = container @ { .cluster == system_cluster, .system };

    log("Adding directory chain to system container");
    val directory_chain_config = map&lt;text,gtv&gt;.from_gtv(chain_context.raw_config);
    val directory_chain_signers = list&lt;byte_array&gt;.from_gtv(directory_chain_config["signers"]);
    add_blockchain(chain_context.raw_config.to_bytes(), directory_chain_signers, blockchains.directory_chain, system_container, true);

    val system_anchoring_config_map = map&lt;text,gtv&gt;.from_gtv(gtv.from_bytes(system_anchoring_config));
    if (system_anchoring_config_map.size() &gt; 0) {
        log("Adding system anchoring blockchain to system container");
        val system_anchoring_blockchain = add_blockchain(system_anchoring_config, directory_chain_signers, blockchains.system_anchoring, system_container, true);
        update system_anchoring_chain ( rid = system_anchoring_blockchain.rid );
    }

    require(directory_chain_signers.size() == 1, "Directory chain must have exactly one initial signer");
    val initial_signer_node_key = directory_chain_signers[0];
    require(initial_signer_node_key == genesis_node.pubkey, "Blockchain signer must match genesis node configuration");

    log("Adding initial signer node of directory chain to system cluster: " + initial_signer_node_key);
    val initial_node = create node(
        provider,
        initial_signer_node_key,
        host = genesis_node.host,
        port = genesis_node.port,
        api_url = genesis_node.api_url,
        last_updated = op_context.last_block_time
    );
    create cluster_node(system_cluster, initial_node);
    node_list.last_update = op_context.last_block_time;
    check_operational(system_cluster);
    log("---------------------------------------------------------------");
}

function _setup_provider_quotas(actions_per_day: integer, max_containers: integer) {
    // max_actions_per_day
    create provider_quota(tier = provider_tier.COMMUNITY_NODE_PROVIDER, provider_quota_type.max_actions_per_day, value = actions_per_day);
    create provider_quota(tier = provider_tier.NODE_PROVIDER, provider_quota_type.max_actions_per_day, value = actions_per_day);
    // max_nodes
    create provider_quota(tier = provider_tier.COMMUNITY_NODE_PROVIDER, provider_quota_type.max_nodes, value = provider_quota_defaults.MAX_NODES);
    create provider_quota(tier = provider_tier.NODE_PROVIDER, provider_quota_type.max_nodes, value = -1);
    // max_containers
    create provider_quota(tier = provider_tier.NODE_PROVIDER, provider_quota_type.max_containers, value = max_containers);
}
</string>
                            </entry>
                            <entry key="common/node.rell">
                                <string>function add_node_internal(provider, node_pubkey: pubkey, host: text, port: integer, api_url: text, clusters: list&lt;text&gt;, cluster_units: integer): node {
    require(empty(provider @? { node_pubkey }), "This pubkey is already registered as a provider: " + node_pubkey);
    require(empty(node @? { node_pubkey }), "Node already exists: " + node_pubkey);
    require_provider_quota(provider, provider_quota_type.max_nodes);
    val node = create node(provider, node_pubkey, host, port = port, api_url = api_url, last_updated = op_context.last_block_time, cluster_units = cluster_units);
    for (cluster_name in clusters) {
        val cluster = require_cluster(cluster_name);
        if (roles.has_node_access(provider)) {
            add_node_to_cluster_internal(provider, node, cluster);
        } else { // provider_tier.COMMUNITY_NODE_PROVIDER
            _add_replica_node_to_cluster_internal(cluster, node);
        }
        node_list.last_update = op_context.last_block_time;
    }
    after_node_added(node);
    return node;
}

function require_node_provider(node_pubkey: pubkey, provider_pubkey: pubkey) {
    val provider = require(provider @? { provider_pubkey }, "Provider %s does not exist".format(provider_pubkey));
    require_provider_auth_with_rate_limit(provider);
    val node = require_node(node_pubkey);
    require(node.provider == provider, "Must be provider of node to update its state");
    return node;
}

function require_cluster_units_for_node(cluster, node) {
    val available_cluster_units = get_available_cluster_units_for_node(node);
    require(available_cluster_units &gt;= cluster.cluster_units,
        "Node %s has %d cluster unit(s). To support cluster %s %d more unit(s) are required."
            .format(node.pubkey, node.cluster_units, cluster.name, cluster.cluster_units - available_cluster_units));
}

function get_available_cluster_units_for_node(node): integer {
    return node.cluster_units - get_used_cluster_units_for_node(node);
}

function get_used_cluster_units_for_node(node): integer {
    return (cluster_node, cluster) @ { node, cluster_node.cluster == cluster } (@sum cluster.cluster_units) +
        (cluster_replica_node, cluster) @ { node, cluster_replica_node.cluster == cluster } (@sum cluster.cluster_units);
}

@extendable function after_node_added(node) {}
</string>
                            </entry>
                            <entry key="common/operations/common_operations_blockchain.rell">
                                <string>operation add_blockchain_replica(my_pubkey: pubkey, blockchain_rid: byte_array, node_pubkey: byte_array) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val node = require_node(node_pubkey);
    val blockchain = require_blockchain(blockchain_rid);
    require(empty(blockchain_replica_node @? { blockchain, node }), "Node is already a replica of blockchain %s".format(node.pubkey, blockchain.rid));
    require(node.provider == provider, "It is only allowed to add own node as a blockchain replica");
    create blockchain_replica_node(blockchain, node);
}

operation remove_blockchain_replica(my_pubkey: pubkey, blockchain_rid: byte_array, node_pubkey: byte_array) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val blockchain = require_blockchain(blockchain_rid);
    val node = require_node(node_pubkey);
    require(node.provider == provider, "It is only allowed to remove own blockchain replica node; provider:%s, node: %s".format(provider.pubkey, node.pubkey));
    delete blockchain_replica_node @? { blockchain, node };
}</string>
                            </entry>
                            <entry key="common/operations/common_operations_cluster.rell">
                                <string>/**
 * Adding a node to a cluster automatically makes it signer of all bc in this cluster.
 * Only one node per provider and cluster.
 */
operation add_node_to_cluster(my_pubkey: pubkey, node_pubkey: pubkey, cluster_name: text) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val cluster = require_cluster(cluster_name);
    val node = require_node(node_pubkey);
    add_node_to_cluster_internal(provider, node, cluster);
}

operation add_replica_node_to_cluster(my_pubkey: pubkey, node_pubkey: pubkey, cluster_name: text) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val cluster = require_cluster(cluster_name);
    val node = require_node(node_pubkey);
    require(empty(cluster_replica_node @* { cluster, node }), "Node %s is already a replica of the cluster %s".format(node_pubkey, cluster_name));
    require(node.provider == provider, "It is only allowed to add own node as a container replica");
    require(empty(cluster_node @* { cluster, node }), "Node %s is a cluster node and can't be added to cluster %s as a replica node".format(node_pubkey, cluster_name));
    _add_replica_node_to_cluster_internal(cluster, node);
}

operation remove_replica_node_from_cluster(my_pubkey: pubkey, node_pubkey: pubkey, cluster_name: text) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val cluster = require_cluster(cluster_name);
    val node = require_node(node_pubkey);
    require(exists(cluster_replica_node @* { cluster, node }), "Node %s is not a replica of the cluster %s".format(node_pubkey, cluster_name));
    require(node.provider == provider, "It is only allowed to remove own container replica node");
    _remove_replica_node_from_cluster_internal(node);
}</string>
                            </entry>
                            <entry key="common/operations/common_operations_container.rell">
                                <string>operation remove_container(me: pubkey, container_name: text) {
    val provider = require_is_provider_with_rate_limit(me);
    val container = require_container(container_name);
    require_cluster_governor(container.cluster, provider);
    require_container_available_for_removal(container);
    remove_container_and_voter_set(container);
}</string>
                            </entry>
                            <entry key="common/operations/common_operations_node.rell">
                                <string>operation register_node(my_pubkey: pubkey, node_pubkey: pubkey, host: text, port: integer, api_url: text, clusters:list&lt;text&gt; = list&lt;text&gt;()) {
    register_node_with_units_impl(my_pubkey, node_pubkey, host, port, api_url, clusters, 1);
}

operation register_node_with_units(my_pubkey: pubkey, node_pubkey: pubkey, host: text, port: integer, api_url: text, clusters:list&lt;text&gt; = list&lt;text&gt;(), cluster_units: integer) {
    register_node_with_units_impl(my_pubkey, node_pubkey, host, port, api_url, clusters, cluster_units);
}

function register_node_with_units_impl(my_pubkey: pubkey, node_pubkey: pubkey, host: text, port: integer, api_url: text, clusters:list&lt;text&gt; = list&lt;text&gt;(), cluster_units: integer) {
    log("------------- Register-Node: %s --------------".format(node_pubkey));
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    require_pubkey(node_pubkey);
    add_node_internal(provider, node_pubkey, host, port, api_url, clusters, cluster_units);
    log("Added node information for node: " + node_pubkey);
    log("-----------------------------------");
}

operation replace_node(my_pubkey: pubkey, old_node_key: pubkey, new_node_key: pubkey, new_host: text?, new_port: integer?, new_api_url: text?) {
    replace_node_with_units_impl(my_pubkey, old_node_key, new_node_key, new_host, new_port, new_api_url, 1);
}

operation replace_node_with_units(my_pubkey: pubkey, old_node_key: pubkey, new_node_key: pubkey, new_host: text?, new_port: integer?, new_api_url: text?, cluster_units: integer) {
    replace_node_with_units_impl(my_pubkey, old_node_key, new_node_key, new_host, new_port, new_api_url, cluster_units);
}

function replace_node_with_units_impl(my_pubkey: pubkey, old_node_key: pubkey, new_node_key: pubkey, new_host: text?, new_port: integer?, new_api_url: text?, new_cluster_units: integer) {
    log("------------- Replace-Node: %s --------------".format(old_node_key));
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_signer(old_node_key);
    require_is_signer(new_node_key);
    val old_node = node @ { old_node_key };
    require(old_node.provider == me, "Node must be owned by provider");
    val old_cluster_units_used = get_used_cluster_units_for_node(old_node);
    require(new_cluster_units &gt;= old_cluster_units_used, "Node must have at least %d cluster_units".format(old_cluster_units_used));

    val host = new_host ?: old_node.host;
    val port = new_port ?: old_node.port;
    val api_url = new_api_url ?: old_node.api_url;

    val cluster_names = cluster_node @* { old_node }.cluster.name;
    delete cluster_node @* { old_node };
    val clusters_replicated_by_node = cluster_replica_node @* { old_node } (.cluster);
    delete cluster_replica_node @* { old_node };
    val blockchains_replicated_by_node = blockchain_replica_node @* { old_node } (.blockchain);
    delete blockchain_replica_node @* { old_node };

    delete old_node;
    add_node_internal(me, new_node_key, host, port, api_url, cluster_names, new_cluster_units);

    val new_node = node @ { new_node_key };
    for (cl in clusters_replicated_by_node) {
        _add_replica_node_to_cluster_internal(cl, new_node);
    }

    for (blockchain in blockchains_replicated_by_node) {
        if (not(exists(blockchain_replica_node @? { blockchain, new_node }))) {
            create blockchain_replica_node(blockchain, new_node);
        }
    }

    node_list.last_update = op_context.last_block_time;
    log("---------------------------------------");
}

operation enable_node(my_pubkey: pubkey, node_pubkey: pubkey) {
    log("------------- Enable-Node: %s --------------".format(node_pubkey));
    val provider = require_is_provider_with_rate_limit(my_pubkey);
    val node = require_node(node_pubkey);
    require(node.provider == provider, "Node must be owned by provider: " + node_pubkey);
    require(not(node.active), "Node is already active: " + node_pubkey);
    node.active = true;
    after_node_added(node);
    log("-----------------------------------");
}


operation disable_node(my_pubkey: pubkey, node_pubkey: pubkey) {
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val node_to_disable = require_node(node_pubkey);

    if (provider != node_to_disable.provider) {
        require(roles.has_system_access(provider), "Non system provider is only allowed to disable own nodes");
        require(
            node_to_disable.provider.tier == provider_tier.NODE_PROVIDER and not(node_to_disable.provider.system),
            "System provider is only allowed to disable nodes of non system provider");
    }

    node_to_disable.active = false;

    // cluster nodes
    val clusters = cluster_node @* { node_to_disable } .cluster;
    delete cluster_node @* { node_to_disable };
    for (cl in clusters) {
        update_configuration_signers(cl, node_to_disable);
    }

    // cluster replica nodes
    delete cluster_replica_node @* { .node.pubkey == node_pubkey };
    // blockchain replica nodes
    delete blockchain_replica_node @* { .node.pubkey == node_pubkey };

    // updating node list timestamp
    node_list.last_update = op_context.last_block_time;
}

operation remove_node(my_pubkey: pubkey, node_pubkey: pubkey) {
    log("------------- Remove-Node: %s --------------".format(node_pubkey));
    val provider = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(provider);
    val node_to_remove = require_node(node_pubkey);
    require(provider == node_to_remove.provider, "It is only allowed to remove own nodes: " + node_pubkey);
    require(not(node_to_remove.active), "Can't remove active nodes: " + node_pubkey);
    delete node_to_remove;
    log("---------------------------------------");
}

operation update_node(my_pubkey: pubkey, node_pubkey: pubkey, host: text? = null, port: integer? = null, api_url: text? = null) {
    update_node_with_units_impl(my_pubkey, node_pubkey, host, port, api_url, null);
}

operation update_node_with_units(my_pubkey: pubkey, node_pubkey: pubkey, host: text? = null, port: integer? = null, api_url: text? = null, cluster_units: integer? = null) {
    update_node_with_units_impl(my_pubkey, node_pubkey, host, port, api_url, cluster_units);
}

function update_node_with_units_impl(my_pubkey: pubkey, node_pubkey: pubkey, host: text?, port: integer?, api_url: text?, cluster_units: integer?) {
    val node = require_node_provider(node_pubkey, my_pubkey);
    if (host != null) node.host = host;
    if (port != null) node.port = port;
    if (api_url != null) node.api_url = api_url;
    if (host != null or port != null or api_url != null) node.last_updated = op_context.last_block_time;
    if (host != null or port != null) node_list.last_update = op_context.last_block_time;
    if (cluster_units != null) {
        require(cluster_units &gt; 0, "Node must have at least 1 cluster_unit");
        val needed_cluster_units = get_used_cluster_units_for_node(node);
        require(cluster_units &gt;= needed_cluster_units,
            "Can not update cluster units to %d since the node needs at least %d to support current clusters.".format(cluster_units, needed_cluster_units));
        node.cluster_units = cluster_units;
    }
}

operation update_node_capability(my_pubkey: pubkey, node_pubkey: pubkey, type: node_capability_type, add: boolean) {
    val node = require_node_provider(node_pubkey, my_pubkey);
    if (add) {
        require(node_capabilities @? { node, type } == null, "Node already has this cabability");
        create node_capabilities(node, type);
    } else {
        require(node_capabilities @? { node, type } != null, "Node does not have this capability");
        delete node_capabilities @ { node, type };
    }
}</string>
                            </entry>
                            <entry key="common/operations/common_operations_provider.rell">
                                <string>/*
    The provider with type in line can (+) / can not (-) register a provider with the type in the column:

         | CNP | NP
    -----|-----|-----
     CNP |  +  |  -
     NP  |  +  |  -
     SP  |  +  |  +
*/
operation register_provider(my_pubkey: pubkey, pubkey, provider_tier) {
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    require_pubkey(pubkey);
    require(empty(provider @* { pubkey }), "Provider already exists: " + pubkey);

    register_and_enable_provider(
        provider_info(pubkey),
        provider_tier,
        cluster = null,
        voter_set = null,
        enabled_by_default = _is_node_provider(me.tier) and not(_is_node_provider(provider_tier))
    );
    if (_is_node_provider(provider_tier)) {
        require(roles.has_system_access(me), "Must be system provider to add a node provider");
        enroll.node(provider @ { pubkey });
    }
}

operation promote_node_provider(my_pubkey: pubkey, provider_pubkey: pubkey) { // TODO: Should be able to demote
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_system_provider(my_pubkey);
    val p = require_provider(provider_pubkey);
    require(p.tier != provider_tier.NODE_PROVIDER, "Provider already has this role");
    enroll.node(p);
}


operation transfer_action_points(from: pubkey, to: pubkey, amount: integer) {
    val _from = require_is_provider_with_rate_limit(from);
    val _to = require_provider(to);
    require(provider_rl_state @ { _from } .points &gt;= amount, "Not enough action points to transfer from.");
    update provider_rl_state @ { _from } ( .points -= amount );
    update provider_rl_state @ { _to } ( .points += amount );
}</string>
                            </entry>
                            <entry key="common/operations/module.rell">
                                <string>module;

import ^.*;
import model.*;</string>
                            </entry>
                            <entry key="common/provider.rell">
                                <string>function _is_node_provider(tier: provider_tier) = tier == provider_tier.NODE_PROVIDER;

@extendable function register_and_enable_provider(provider_info, provider_tier, cluster?, voter_set?, enabled_by_default: boolean = false) {
    require(empty(node @? { provider_info.pubkey }), "This pubkey is already registered as a node: " + provider_info.pubkey);
    val provider = create provider(
        provider_info.pubkey,
        name = provider_info.name,
        url = provider_info.url,
        active = enabled_by_default,
        tier = provider_tier
    );
    create provider_rl_state(provider, points = 100, last_update=op_context.last_block_time);
    if (exists(cluster)) {
        create cluster_provider(cluster, provider);
    }
    if (exists(voter_set)) {
        create voter_set_member(voter_set, provider);
    }
}

// Recover provider's action points and consume one, if possible
function provider_rate_limit(provider) {
    val max_actions_per_day = provider_quota @ {
            .tier == provider.tier,
            provider_quota_type.max_actions_per_day
    } .value;

    // We recover max_actions_per_day in 24 hours, find time needed to recover 1 point
    val recovery_time = (86400 * 1000) / max_actions_per_day;
    val state = provider_rl_state @ { provider } (.points, .last_update);
    val time_delta = op_context.last_block_time - state.last_update;
    var got_points = 0;
    var update_time = state.last_update;

    if (time_delta &gt; recovery_time)
    {
        got_points = time_delta / recovery_time;
        // advance  update_time to a multiple of recovery_time to avoid wasting time
        update_time = state.last_update + got_points * recovery_time;
        if (got_points + state.points &gt; max_actions_per_day) {
            got_points = max_actions_per_day - state.points;
            // if user is at the maximum reset his timer
            update_time = op_context.last_block_time;
        }
    }

    require(state.points + got_points &gt; 0, "Provider has no points to spend: " + provider.pubkey);

    update provider_rl_state @ { provider } (
        .points += got_points - 1,
        .last_update = update_time
    );
}

function require_provider_quota(provider, quota_type: provider_quota_type) {
    val quota = provider_quota @ { provider.tier, quota_type } (.value);
    if (quota &gt; 0) {
        when (quota_type) {
            max_nodes -&gt; _require_provider_quota(quota, quota_type, node @ { provider } (@sum 1));
            max_containers -&gt; _require_provider_quota(quota, quota_type, container @ { provider, .system == false } (@sum 1));
        }
    }
}

function _require_provider_quota(quota: integer, quota_type: provider_quota_type, count: integer) {
    require(count &lt; quota , "Provider quota exceeded: %s = %d".format(quota_type, quota));
}
</string>
                            </entry>
                            <entry key="common/queries/common_queries_anchoring.rell">
                                <string>
query get_cluster_anchoring_configuration(): byte_array {
    return cluster_anchoring_config.raw_config;
}
</string>
                            </entry>
                            <entry key="common/queries/common_queries_blockchain.rell">
                                <string>query get_blockchain(rid: byte_array) = blockchain @ { rid };

query get_blockchain_signers(blockchain_rid: byte_array): list&lt;(byte_array, text, integer, boolean, integer)&gt; {
    val blockchain = require_blockchain(blockchain_rid, true);
    return get_blockchain_signer_nodes(blockchain) @* {} (
            @sort _ = .pubkey,
            _ = .host,
            _ = .port,
            _ = .active,
            _ = .last_updated
        );
}

query get_blockchain_replicas(blockchain_rid: byte_array) {
    return blockchain_replica_node @* { .blockchain.rid == blockchain_rid } (
        @sort .node.pubkey,
        .node.host,
        .node.port,
        .node.active,
        .node.last_updated
    );
}

query get_blockchains(include_inactive: boolean): list&lt;struct&lt;blockchain&gt;&gt; {
    if (include_inactive) {
        return blockchain @* {} ($.to_struct());
    }
    return blockchain @* { .state == blockchain_state.RUNNING } ($.to_struct());
}

// Will return RUNNING and PAUSED if include_inactive == true
function get_blockchains_with_container(include_inactive: boolean) {
    if (include_inactive) {
        return (b: blockchain, c: container_blockchain) @* { c.blockchain == b } (blockchain=b, c.container) ;
    } else {
        return (b: blockchain, c: container_blockchain) @* { c.blockchain == b and b.state == blockchain_state.RUNNING } (blockchain = b, c.container);
    }
}

// Will return RUNNING, PAUSED and REMOVED if include_inactive == true
query get_blockchain_info_list(include_inactive: boolean): list&lt;(rid: byte_array, name: text, state: blockchain_state, container: name?, cluster: name?)&gt; {
    var bc_infos = list&lt;(blockchain: blockchain, container: container?)&gt;();
    if (include_inactive) {
        val connected_blockchains = container_blockchain @* {} (.blockchain, .container);
        val removed_blockchains = blockchain @* {
            blockchain not in connected_blockchains @* {}.blockchain
        } (blockchain = blockchain, container = null);
        bc_infos.add_all(connected_blockchains);
        bc_infos.add_all(removed_blockchains);
    } else {
        bc_infos.add_all((b: blockchain, c: container_blockchain) @* { c.blockchain == b and b.state == blockchain_state.RUNNING } (blockchain = b, c.container));
    }
    
    val result = list&lt;(rid: byte_array, name: text, state: blockchain_state, container: name?, cluster: name?)&gt;();
    for (bc in bc_infos) {
        result.add((
            rid = bc.blockchain.rid,
            name = bc.blockchain.name,
            state = bc.blockchain.state,
            container = bc.container?.name,
            cluster = bc.container?.cluster?.name
        ));
    }
    return result;
}

query get_blockchain_cluster(blockchain_rid: byte_array) = cm_get_blockchain_cluster(blockchain_rid);

query get_blockchain_api_urls(blockchain_rid: byte_array) = cm_get_blockchain_api_urls(blockchain_rid);

</string>
                            </entry>
                            <entry key="common/queries/common_queries_cluster.rell">
                                <string>
query get_cluster(name) = cluster @ { name };

query get_clusters() {
    return cluster @* {} (
        name = .name,
        governor = .governance.name,
        operational = .operational
    );
}

struct cluster_data {
    name;
    governor: text;
    is_operational: boolean;
    cluster_units: integer?;
}

query get_cluster_data(name) {
    val cluster = require_cluster(name);
    return cluster_data(
        name = cluster.name,
        governor = cluster.governance.name,
        is_operational = cluster.operational,
        cluster_units = cluster.cluster_units
    );
}

query get_cluster_providers(name): list&lt;(name:text, pubkey:pubkey)&gt; {
    val cluster = require_cluster(name);
    return cluster_provider @* { cluster } (name = .provider.name, pubkey = .provider.pubkey);
}

query get_cluster_nodes(name) {
    val cluster = require_cluster(name);
    return cluster_node @* { cluster } (
        pubkey = .node.pubkey,
        host = .node.host,
        port = .node.port,
        api_url = .node.api_url,
        active = .node.active
    );
}

query get_cluster_replica_nodes(name) {
    val cluster = require_cluster(name);
    return cluster_replica_node @* { cluster } (
        pubkey = .node.pubkey,
        host = .node.host,
        port = .node.port,
        api_url = .node.api_url,
        active = .node.active
    );
}

query get_cluster_containers(cluster_name: text): list&lt;(name:text, deployer:text)&gt; {
    return container @* { .cluster.name == cluster_name } ( @sort name = .name, deployer = .deployer.name);
}

query get_cluster_blockchains(name) = cm_get_cluster_blockchains(name);

query get_cluster_api_urls(name) {
    return (cluster_node, cluster) @* { cluster.name == name and cluster == cluster_node.cluster } ( cluster_node.node.api_url );
}

</string>
                            </entry>
                            <entry key="common/queries/common_queries_container.rell">
                                <string>
query get_container(name) = container @ { name };

query get_container_data(name) {
    val container = require_container(name);
    return (
        name = container.name,
        cluster = container.cluster.name,
        deployer = container.deployer.name,
        proposed_by_pubkey = container.proposed_by.pubkey,
        proposed_by_name = container.proposed_by.name,
        system = container.system
    );
}

query get_container_blockchain(name) {
    val container = require_container(name);
    return container_blockchain @* { container } (
        rid = .blockchain.rid,
        name = .blockchain.name,
        system = .blockchain.system,
        state = .blockchain.state
    );
}

query get_containers(): list&lt;(cluster:text, name:text, deployer:text)&gt; {
    return container @* {} (@sort cluster = .cluster.name, @sort name = .name, deployer = .deployer.name);
}
</string>
                            </entry>
                            <entry key="common/queries/common_queries_node.rell">
                                <string>
query get_node(pubkey) = node @ { pubkey };

struct node_data {
    provider: pubkey;
    pubkey;
    active: boolean;
    host: text;
    port: integer;
    last_updated: timestamp;
    api_url: text;
    cluster_units: integer?;
}

query get_node_data(pubkey) {
    val node = require_node(pubkey);
    return node_data(
        provider = node.provider.pubkey,
        pubkey = node.pubkey,
        active = node.active,
        host = node.host,
        port = node.port,
        last_updated = node.last_updated,
        api_url = node.api_url,
        cluster_units = node.cluster_units
    );
}

query list_clusters_of_node(pubkey): list&lt;text&gt; {
    val node = require_node(pubkey);
    return cluster_node @* { node }.cluster.name;
}

query get_node_containers(pubkey): list&lt;(cluster:text, name:text, deployer:text)&gt; {
    val node = require_node(pubkey);
    val clusters = cluster_node @* { node } .cluster;
    val res = list&lt;(cluster:text, name:text, deployer:text)&gt;();
    for (cl in clusters) {
        val containers = container @* { cl } (@sort cluster = .cluster.name, @sort name = .name, deployer = .deployer.name);
        res.add_all(containers);
    }
    return res;
}

// deprecated
query get_nodes_with_provider() {
    return node @* {} (
        pubkey = .pubkey,
        node_active = .active,
        host = .host,
        port = .port,
        last_updated = .last_updated,
        name = .provider.name,
        provider_active = .provider.active,
        @sort provider = .provider.pubkey
    );
}

query get_all_nodes(include_inactive: boolean) {
    val nodes = if (include_inactive) node @* {} else node @* { .active };
    return nodes @* {} (
        info = node_info(.pubkey, host = .host, port = .port, api_url = .api_url),
        active = .active,
        last_updated = .last_updated,
        provider = .provider.to_struct()
    );
}
</string>
                            </entry>
                            <entry key="common/queries/common_queries_provider.rell">
                                <string>
query get_provider (pubkey) = provider @ { pubkey };

query get_nodes_by_provider(pubkey) {
    return node @* { provider @ { pubkey } } (
        .pubkey,
        .active,
        .host,
        .port,
        .api_url,
        .last_updated
    );
}

query get_provider_points(pubkey): integer {
    return provider_rl_state @ {provider @ { pubkey }} .points;
}

query get_provider_clusters(pubkey) : list&lt;text&gt; {
    return cluster_provider @* { provider @ {pubkey} }.cluster.name;
}

query get_provider_data (pubkey) {
    return provider @ { pubkey } ($.to_struct());
}

query get_all_providers(): list&lt;struct&lt;provider&gt;&gt; {
    return provider @* {} ($.to_struct());
}

query get_providers(tier: provider_tier, system: boolean, require_active: boolean): list&lt;struct&lt;provider&gt;&gt; {
    if (system) {
        require(tier == provider_tier.NODE_PROVIDER, "System providers are always node providers");
    }
    return  provider @* { 
        tier,
        if (system) .system else true, 
        if (require_active) .active else true 
     } ($.to_struct());
}

query get_provider_quotas(): list&lt;struct&lt;provider_quota&gt;&gt; {
    return provider_quota @* {} ($.to_struct());
}
</string>
                            </entry>
                            <entry key="common/queries/common_queries_voter_set.rell">
                                <string>query list_voter_sets() {
    return voter_set@* {} ( voter_set.to_struct() );
}

query get_voter_set_info(name): (name:text, threshold:integer, governor:text, members:list&lt;pubkey&gt;) {
    val v = require(voter_set @? { name }, "Voter set " + name + " not found");
    val governance = voter_set_governance @ { .voter_set == v };
    val members = voter_set_member @* { v } ( .provider.pubkey );
    return (
        name = v.name,
        threshold = v.threshold,
        governor = governance.governor.name,
        members = members
    );
}

query get_voter_set(name) = voter_set @ { name };

query get_voter_set_governor(name) {
    return voter_set_governance @ { .voter_set == voter_set @ { name } } .governor.name;
}

query get_voter_set_members(name) {
    return voter_set_member @* {voter_set @ {name}} (.provider.pubkey);
}

query get_voter_sets() {
    return (voter_set, voter_set_governance) @* { voter_set == voter_set_governance.voter_set } (name = voter_set.name, threshold = voter_set.threshold, @sort gorvernor = voter_set_governance.governor.name);
}</string>
                            </entry>
                            <entry key="common/queries/module.rell">
                                <string>module;

import ^.*;
import cm_api.*;
import model.*;

query get_summary() {
    return (
        providers = provider @{} (@sum 1),
        clusters = cluster @{} (@sum 1),
        containers = container @{} (@sum 1),
        voter_sets = voter_set @{} (@sum 1),
        nodes = node @{} (@sum 1),
        blockchains = blockchain @{} (@sum 1)
    );
}
</string>
                            </entry>
                            <entry key="common/require.rell">
                                <string>function require_is_signer(pubkey) {
    require(op_context.is_signer(pubkey), "Operation must be signed by " + pubkey);
}

function require_provider(pubkey) = require(provider @? { pubkey }, "Unknown provider " + pubkey);
function require_cluster(name) = require(cluster @? { name }, "Cluster %s not found".format(name));
function require_node(pubkey) = require(node @? { pubkey }, "Node not found: " + pubkey);
function require_container(name) = require(container @? { name }, "Container %s not found".format(name));
function require_voter_set(name) = require(voter_set @? { name }, "Voter set %s does not exist".format(name));
function require_blockchain_entity(blockchain_rid: byte_array) = require(blockchain @? { blockchain_rid }, "Unknown blockchain " + blockchain_rid);
function require_blockchain(
    blockchain_rid: byte_array,
    require_running: boolean = false,
    include_removed: boolean = false) = require(
        blockchain @? {
            blockchain_rid,
            include_removed or
            (require_running and .state == blockchain_state.RUNNING) or
            .state in [blockchain_state.RUNNING, blockchain_state.PAUSED]
        }, "Unknown blockchain " + blockchain_rid);

function require_is_system_provider(pubkey) {
    val p = require_provider(pubkey);
    require_system_access(p);
    return p;
}

function require_system_p_member(provider) {
    require_voter_set_member(system_p_voter_set(), provider);
}

function require_cluster_governor(cluster, provider) {
    require_voter_set_member(cluster.governance, provider);
}

function require_voter_set_governor(voter_set, provider) {
    val governor = voter_set_governance @ { voter_set } .governor;
    require_voter_set_member(governor, provider);
}

function require_container_deployer(container, provider) {
    require(roles.has_deploy_access(provider, container), "Provider %s is not a deployer of container %s".format(provider.pubkey, container.name));
}

function require_voter_set_member(voter_set, provider) {
    require(exists(voter_set_member @* { voter_set, provider}), "Provider is not a member of voter set " + voter_set.name);
}

function require_is_provider_with_rate_limit(pubkey) {
    val provider = require_provider(pubkey);
    require_provider_auth_with_rate_limit(provider);
    return provider;
}

// This is the function we should use for auth
function require_provider_auth_with_rate_limit(provider) {
    require_is_signer(provider.pubkey);
    provider_rate_limit(provider);
}

function require_pubkey(pubkey) {
    require(pubkey.size() == 33 or pubkey.size() == 65 or pubkey.size() == 1336, "Value is not pubkey: " + pubkey);
}</string>
                            </entry>
                            <entry key="common/util.rell">
                                <string>function make_config_unique(config_data: byte_array): byte_array {
    val config_map = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data));

    val chain0_block_rid = if (op_context.block_height &gt;= 1)
        block @ { .block_height == op_context.block_height - 1 } ( .block_rid )
    else
        chain_context.blockchain_rid;
    config_map["chain0_last_block_rid"] = chain0_block_rid.to_gtv();
    config_map["chain0_block_height"] = op_context.block_height.to_gtv();
    config_map["chain0_tx_rid"] = op_context.transaction.tx_rid.to_gtv();
    config_map["chain0_op_index"] = op_context.op_index.to_gtv();

    return config_map.to_gtv().to_bytes();
}
</string>
                            </entry>
                            <entry key="direct_cluster/cluster_op.rell">
                                <string>// Creates a cluster with a set of providers
operation create_cluster(my_pubkey: pubkey, name, governor_voter_set: text, provider_pubkeys: list&lt;pubkey&gt;) {
    create_cluster_with_units_impl(my_pubkey, name, governor_voter_set, provider_pubkeys, standard_cluster_defaults.cluster_units);
}

operation create_cluster_with_units(my_pubkey: pubkey, name, governor_voter_set: text, provider_pubkeys: list&lt;pubkey&gt;, cluster_units: integer) {
    create_cluster_with_units_impl(my_pubkey, name, governor_voter_set, provider_pubkeys, cluster_units);
}

function create_cluster_with_units_impl(my_pubkey: pubkey, name, governor_voter_set: text, provider_pubkeys: list&lt;pubkey&gt;, cluster_units: integer) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_system_access(me);
    val governor = require_voter_set(governor_voter_set);
    create_cluster_impl(me, name, governor, provider_pubkeys, cluster_units);
}

// Creates a cluster provided by the members of an existing voter set
operation create_cluster_from(my_pubkey: pubkey, name, governor_voter_set: text, provider_voter_set: text) {
    create_cluster_from_with_units_impl(my_pubkey, name, governor_voter_set, provider_voter_set, standard_cluster_defaults.cluster_units);
}

operation create_cluster_from_with_units(my_pubkey: pubkey, name, governor_voter_set: text, provider_voter_set: text, cluster_units: integer) {
    create_cluster_from_with_units_impl(my_pubkey, name, governor_voter_set, provider_voter_set, cluster_units);
}

function create_cluster_from_with_units_impl(my_pubkey: pubkey, name, governor_voter_set: text, provider_voter_set: text, cluster_units: integer) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_system_access(me);
    val governor = require_voter_set(governor_voter_set);
    val node_provider_set = require_voter_set(provider_voter_set);
    create_cluster_impl(me, name, governor, voter_set_member @* { node_provider_set }.provider.pubkey, cluster_units);
}

operation request_cluster(my_pubkey: pubkey, name, size: integer, require_full: boolean) {
    request_cluster_with_units_impl(my_pubkey, name, size, require_full, standard_cluster_defaults.cluster_units);
}

operation request_cluster_with_units(my_pubkey: pubkey, name, size: integer, require_full: boolean, cluster_units: integer) {
    request_cluster_with_units_impl(my_pubkey, name, size, require_full, cluster_units);
}

function request_cluster_with_units_impl(my_pubkey: pubkey, name, size: integer, require_full: boolean, cluster_units: integer) {
    require(size &gt;= 4, "At least 4 nodes should be requested to be able to reach bft majority");
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_system_access(me);

    val possible_nodes = (node, node_capabilities) @* { 
        node_capabilities.node == node,
        node_capabilities.type == node_capability_type.SYSTEM_MANAGED,
        not(.pubkey in cluster_node @* {} (.node.pubkey)) 
        }.node;
    val available_nodes: list&lt;node&gt; = list&lt;node&gt;();
    for (pnode in possible_nodes) {
        if (get_available_cluster_units_for_node(pnode) &gt;= cluster_units) available_nodes.add(pnode);
    }
    val unique_providers = set&lt;provider&gt;();
    unique_providers.add_all(available_nodes @* {}.provider);
    val chosen_providers = unique_providers @* {} limit size;
    require(chosen_providers.size() &gt;= 4, "Clusters can only be created when at least four nodes are available");
    require(chosen_providers.size() == size or not(require_full), "Not enough providers have available nodes, found %d, requested %d".format(chosen_providers.size(), size));

    log("Creating cluster " + name + " with providers " + chosen_providers @*{}.pubkey);
    val cluster = create_cluster_impl(me, name, system_voter_set(), chosen_providers @* {}.pubkey, cluster_units);
    for (p in chosen_providers) {
        val node = available_nodes @ { .provider == p } limit 1;
        add_node_to_cluster_internal(p, node, cluster);
    }
}</string>
                            </entry>
                            <entry key="direct_cluster/module.rell">
                                <string>module;

import common.*;
import model.*;</string>
                            </entry>
                            <entry key="direct_container/container_op.rell">
                                <string>// consensus_threshold: majority (-1), super majority (0) or custom (1, ...)
operation create_container(me: pubkey, name, cluster_name: text, consensus_threshold: integer, deployers: list&lt;pubkey&gt;) {
    create_container_with_units_impl(me, name, cluster_name, consensus_threshold, deployers, standard_container_defaults.container_units);
}

// consensus_threshold: majority (-1), super majority (0) or custom (1, ...)
operation create_container_with_units(me: pubkey, name, cluster_name: text, consensus_threshold: integer, deployers: list&lt;pubkey&gt;, container_units: integer) {
    create_container_with_units_impl(me, name, cluster_name, consensus_threshold, deployers, container_units);
}

// consensus_threshold: majority (-1), super majority (0) or custom (1, ...)
operation create_container_from(me: pubkey, name, cluster_name: text, consensus_threshold: integer, voter_set_name: text) {
    create_container_from_with_units_impl(me, name, cluster_name, consensus_threshold, voter_set_name, standard_container_defaults.container_units);
}

// consensus_threshold: majority (-1), super majority (0) or custom (1, ...)
operation create_container_from_with_units(me: pubkey, name, cluster_name: text, consensus_threshold: integer, voter_set_name: text, container_units: integer) {
    create_container_from_with_units_impl(me, name, cluster_name, consensus_threshold, voter_set_name, container_units);
}

operation add_container_deployer(me: pubkey, container_name: text, deployer_pubkey: pubkey) {
    val provider = require_is_provider_with_rate_limit(me);
    val container = require_container(container_name);
    require_cluster_governor(container.cluster, provider);
    val deployer = require_provider(deployer_pubkey);
    create voter_set_member(container.deployer, deployer);
}

operation remove_container_deployer(me: pubkey, container_name: text, deployer_pubkey: pubkey) {
    val provider = require_is_provider_with_rate_limit(me);
    val container = require_container(container_name);
    require_cluster_governor(container.cluster, provider);
    val deployer = require_provider(deployer_pubkey); 
    delete voter_set_member @? { container.deployer, deployer };
}

function create_container_with_units_impl(me: pubkey, name, cluster_name: text, consensus_threshold: integer, deployers: list&lt;pubkey&gt;, container_units: integer) {
    val provider = require_is_provider_with_rate_limit(me);
    val cluster = require_cluster(cluster_name);
    require_cluster_governor(cluster, provider);
    require_provider_quota(provider, provider_quota_type.max_containers);
    require_cluster_quotas(cluster, container_units);
    create_container_impl(provider, name, cluster, consensus_threshold, deployers, container_units, standard_container_defaults.max_blockchains);
}

function create_container_from_with_units_impl(me: pubkey, name, cluster_name: text, consensus_threshold: integer, voter_set_name: text, container_units: integer) {
    val provider = require_is_provider_with_rate_limit(me);
    val cluster = require_cluster(cluster_name);
    require_cluster_governor(cluster, provider);
    require_provider_quota(provider, provider_quota_type.max_containers);
    require_cluster_quotas(cluster, container_units);
    val vs = require_voter_set(voter_set_name);
    val deployers = voter_set_member @* { vs } (.provider.pubkey);
    create_container_impl(provider, name, cluster, consensus_threshold, deployers, container_units, standard_container_defaults.max_blockchains);
}</string>
                            </entry>
                            <entry key="direct_container/module.rell">
                                <string>module;

import ^.model.*;
import ^.common.*;</string>
                            </entry>
                            <entry key="housekeeping/module.rell">
                                <string>module;

import common.*;

struct module_args {
    max_empty_container_time: integer;
}

@extend (before_delete_blockchain) function set_container_latest_deleted_bc_time(blockchain) {
    val container = container_blockchain @ { blockchain }.container;
    container.latest_bc_removal = op_context.last_block_time;
}

function prune_empty_containers() {
    for (container in container @* {}) {
        val is_removable = empty(is_container_available_for_removal(container));
        if (is_removable and op_context.last_block_time - container.latest_bc_removal &gt; chain_context.args.max_empty_container_time) {
            log("Removing container %s that has been empty since %s".format(container.name, container.latest_bc_removal));
            remove_container_and_voter_set(container);
        }
    }
}
</string>
                            </entry>
                            <entry key="management_chain_directory1/module.rell">
                                <string>module;

import common.*;
import common.init.*;
import common.operations.*;
import common.queries.*;
import direct_cluster.*;
import direct_container.*;
import nm_api.*;
import proposal.*;
import proposal_blockchain.*;
import proposal_blockchain_import.*;
import proposal_cluster.*;
import proposal_cluster_anchoring.*;
import proposal_container.proposal_container_limits.*;
import proposal_provider.*;
import proposal_voter_set.*;
import version;

/*
 * Directory1 is an enterprise dapp where the d1 dapp manages and controls creating and deleting clusters, containers and blockchains.
 * To run this dapp postchain must be started in managed mode and preferably using master/subnode configuration.
 */
operation update_provider(my_pubkey: pubkey, name?, url: text?) {
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    if (exists(name)) me.name = name;
    if (exists(url)) me.url = url;
}

operation __begin_block(height: integer) {
    before_begin_block(height);

    if (empty(blockchain @? { chain_context.blockchain_rid })) return;
    val expected_config = get_blockchain_configuration(chain_context.blockchain_rid, height);
    if (expected_config == null or expected_config.config_hash == chain_context.raw_config.hash()) return;

    log("Chain0 config for height %d changed from %s to %s and will be stored".format(
        height, expected_config.config_hash, chain_context.raw_config.hash()));
    val config_map = map&lt;text, gtv&gt;.from_gtv(chain_context.raw_config);
    config_map.remove_or_null("signers");
    val base_config = config_map.to_gtv().to_bytes();
    create blockchain_configuration(blockchain @ { chain_context.blockchain_rid }, height, base_config);
    add_dependencies(base_config, chain_context.blockchain_rid, height);
}

@extendable function before_begin_block(height: integer) {}
</string>
                            </entry>
                            <entry key="management_chain_testnet/module.rell">
                                <string>module;

import version;
import auth_service.*;
import management_chain_directory1.*;
import housekeeping.*;

@extend(before_begin_block) function after_begin_block_handler(height: integer) {
    prune_empty_containers();
}
</string>
                            </entry>
                            <entry key="messaging/configuration_update_message.rell">
                                <string>module;

import ^.icmf.constants.*;

val configuration_updated_topic = ICMF_TOPIC_GLOBAL_PREFIX + "configuration_updated";
val configuration_failed_topic = ICMF_TOPIC_GLOBAL_PREFIX + "configuration_failed";

struct configuration_updated {
    blockchain_rid: byte_array;
    height: integer;
    config_hash: byte_array;
}

struct configuration_failed {
    blockchain_rid: byte_array;
    height: integer;
    config_hash: byte_array;
}
</string>
                            </entry>
                            <entry key="messaging/icmf/constants.rell">
                                <string>module;

val ICMF_MESSAGE_MAX_SIZE = 16 * 1024 * 1024; // 16 MiB
val ICMF_TOPIC_GLOBAL_PREFIX = "G_";
val ICMF_TOPIC_LOCAL_PREFIX = "L_";</string>
                            </entry>
                            <entry key="messaging/icmf/module.rell">
                                <string>module;

import .constants.*;

function send_message(topic: text, body: gtv) {
    val encoded_body = body.to_bytes();
    require(topic.starts_with(ICMF_TOPIC_GLOBAL_PREFIX) or topic.starts_with(ICMF_TOPIC_LOCAL_PREFIX),
        "Topic must start with " + ICMF_TOPIC_GLOBAL_PREFIX + " or " + ICMF_TOPIC_LOCAL_PREFIX);
    require(encoded_body.size() &lt; ICMF_MESSAGE_MAX_SIZE, "Message body too big, max size is %d bytes".format(ICMF_MESSAGE_MAX_SIZE));

    op_context.emit_event("icmf_message", (topic = topic, body = body, block_height = op_context.block_height).to_gtv_pretty());
}
</string>
                            </entry>
                            <entry key="model/anchoring_model.rell">
                                <string>object system_anchoring_chain {
    mutable rid: byte_array = x"";
}

object cluster_anchoring_config {
    mutable raw_config: byte_array = map&lt;text, gtv&gt;().to_gtv().to_bytes();
}

entity cluster_anchoring_chain {
    key blockchain, cluster;
}
</string>
                            </entry>
                            <entry key="model/blockchain_model.rell">
                                <string>enum blockchain_state {
    RUNNING, PAUSED, REMOVED, IMPORTING
}

entity blockchain { 
    key rid: byte_array; 
    mutable name: text;
    system: boolean = false;
    mutable state: blockchain_state = blockchain_state.RUNNING;
}

entity blockchain_configuration {
    key blockchain, height: integer;
    mutable data: byte_array; // base_config, without signers
}

entity pending_blockchain_configuration {
    key blockchain, minimum_height: integer;
    key blockchain, config_hash: byte_array;
    base_config: byte_array;
    signers: byte_array;
}

entity signer_excluded_from_pending_configuration {
    key blockchain, config_hash: byte_array;
    pubkey;
}

entity faulty_blockchain_configuration {
    key blockchain, reported_at_height: integer;
    config_hash: byte_array;
}

entity blockchain_configuration_signers {
    key blockchain, height: integer;
    mutable signers: byte_array;
}

entity blockchain_replica_node { 
    key blockchain, node; 
}

/**
* For blockchain dependency tracking. Dependency is not static.
* Blockchain (me) might be dependent on different blockchains (dependent_on) at different heights.
*/
entity blockchain_dependency { 
    key me: blockchain, height: integer, dependent_on: blockchain; 
}

entity blockchain_configuration_options {
    key blockchain, height: integer;
    suppress_special_transaction_validation: boolean;
}
</string>
                            </entry>
                            <entry key="model/cluster_model.rell">
                                <string>/* Governance semantics:
 *
 * Anybody can create a cluster, but it consumes an action point.
 *
 * A cluster defines a list of providers involved in it. Each provider is supposed to contribute one node.
 * Cluster is considered operational only once every provider specified in a cluster have provided a node.
 * Cluster composition (providers) can change, operational status does not change if new provider is added
 * or a provider disables its node (if it is not the last node of the cluster).
 *
 * Cluster composition can be changed by its 'governance' voter set, they can vote to add or remove providers
 *
 * a provider can add at most one node to a cluster he is a member of. he can also replace his node.
 *
 * Cluster's deployer can add containers, specifying their resource limits. He can change limits for existing containers.
 *
 * Container deployer can deploy, update and stop blockchains in the container.
 *
 *
 * Node can belong to multiple clusters. Although it is not recommended, but permitted.
 *
 * blockchain_signer_node records are not needed for blockchains which run on a cluster, as list
 * of signer nodes can be deduced from list of nodes of a cluster.
 *
 */

// node cluster
entity cluster {
    key name;
    governance: voter_set; // who controls the cluster
    mutable operational: boolean = false; // cluster goes operational when all providers provide a node
    mutable cluster_units: integer = 1; // how many container_units does the cluster support
}

entity cluster_provider { 
    key cluster, provider; 
}

entity cluster_node { 
    key cluster, node; 
}

entity cluster_replica_node {
    key cluster, node;
}

object standard_cluster_unit {
    mutable container_units: integer = 16;
}

object standard_cluster_defaults {
    mutable cluster_units: integer = 1;
}</string>
                            </entry>
                            <entry key="model/constants.rell">
                                <string>namespace blockchains {
    val directory_chain = "directory_chain";
    val system_anchoring = "system_anchoring";
    val cluster_anchoring_prefix = "cluster_anchoring_";
}

namespace containers {
    val system = "system";
    val system_suffix = "_system";
}

namespace clusters {
    val system = "system";
}

namespace voter_sets {
    val system = "SYSTEM";
    val system_p = "SYSTEM_P";
}

function system_container_name(cluster_name: text) =
    if (cluster_name == clusters.system)
        containers.system
    else
        cluster_name + containers.system_suffix;

function system_container() = container @ { system_container_name(clusters.system) };
function system_cluster() = cluster @ { clusters.system };
function system_voter_set() = voter_set @ { voter_sets.system };

function system_p_voter_set() = voter_set @ { voter_sets.system_p };
</string>
                            </entry>
                            <entry key="model/container_model.rell">
                                <string>enum container_resource_limit_type {
    container_units,
    max_blockchains
}

entity container {
    key name;
    index cluster;
    index deployer: voter_set; // who can deploy and update bcs in this container
    proposed_by: provider;
    system: boolean = false;
    mutable latest_bc_removal: timestamp = if (op_context.exists) op_context.last_block_time else -1;
}

entity container_resource_limit {
    key container, container_resource_limit_type;
    mutable value: integer;
}

//Defines which container a blockchain belongs to
entity container_blockchain { 
    key container, blockchain; 
}

object standard_container_unit {
    mutable cpu: integer = 50; // Percent of cpus, i.e. 50 = 0.5 vCPU
    mutable ram: integer = 2048; // MiB
    mutable io_read: integer = 25; // MiB/s
    mutable io_write: integer = 20; // MiB/s
    mutable storage: integer = 16384; // MiB
}

object standard_container_defaults {
    mutable container_units: integer = 1;
    mutable max_blockchains: integer = 10;
}

object system_container_defaults {
    mutable container_units: integer = 4;
    mutable max_blockchains: integer = -1;
}</string>
                            </entry>
                            <entry key="model/foreign_blockchain_import_model.rell">
                                <string>entity foreign_blockchain_import {
    key blockchain_rid: byte_array;
    pubkey;
    host: text;
    port: integer;
    api_url: text;
    chain0_rid: byte_array;
    mutable up_to_height: integer = -1;
}
</string>
                            </entry>
                            <entry key="model/module.rell">
                                <string>module;</string>
                            </entry>
                            <entry key="model/node_model.rell">
                                <string>
entity node {
    index provider;
    key pubkey;
    mutable active: boolean = true;
    mutable host: text;
    mutable port: integer;
    mutable api_url: text;
    mutable last_updated: timestamp;
    mutable cluster_units: integer = 1;
}

enum node_capability_type {
    SYSTEM_MANAGED
}

entity node_capabilities {
    key node, type: node_capability_type;
}

struct node_info {
    pubkey;
    host: text;
    port: integer;
    api_url: text;
}

/**
    Deprecated: is not relevant for multi-cluster environment
*/
object node_list {
    mutable last_update: timestamp = 0;
}
</string>
                            </entry>
                            <entry key="model/provider_model.rell">
                                <string>enum provider_tier {
    /* Can add replica nodes to any cluster */
    COMMUNITY_NODE_PROVIDER,
    /* Can add signer nodes to any non-system cluster */
    NODE_PROVIDER
}
/*
* A provider is a participant of the mainnet eco system
* - Add a replica node
* - Add a provider (Without privileges)
* - Update their own information
* - Form a new voter set
* - Create a cluster
* - Vote on proposals concerning voter sets you belong to
*/
entity provider {
    key pubkey;
    mutable name: text = "";
    mutable url: text = "";
    mutable active: boolean = false;
    mutable tier: provider_tier = provider_tier.COMMUNITY_NODE_PROVIDER;
    /* System provider can
    * - Add and remove signer nodes to clusters
    * - update the system cluster/voter set
    * - Add provider with any (non-system) privileges
    * - Propose removal of providers
    * - Update cluster configuration
    */
    mutable system: boolean = false;
}

// Type of quota for a provider
enum provider_quota_type {
    max_actions_per_day,
    max_nodes,
    max_containers
}

namespace provider_quota_defaults {
    val MAX_ACTIONS_PER_DAY = 100;
    val MAX_NODES = 1;
    val MAX_CONTAINERS = 2;
}

entity provider_quota {
    index tier: provider_tier, provider_quota_type;
    mutable value: integer;
}

// Limit how much stuff provider can do to prevent abuse,
// such as starting billion nodes, etc.
entity provider_rl_state {
    key provider;
    mutable points: integer;
    mutable last_update: integer;
}

struct provider_info {
	pubkey;
	name = "";
	url: text = "";
}</string>
                            </entry>
                            <entry key="model/voter_set_model.rell">
                                <string>/**
* A voter set is a set of providers who are part of a governance process.
* The threshold determines how consensus is achieved.
*/
entity voter_set {
    key name;
    // special values for threshold:
    // 0: super-majority of voters, specifically  `n - (n - 1) / 3` (which is usually around 67%)
    // -1: simple majority
    // positive number: that many voters
    mutable threshold: integer = 0;
}

/**
* Voter set governance determines who is allowed to change an voter set.
*/
entity voter_set_governance {
    key voter_set;
    mutable governor: voter_set;
}

entity voter_set_member {
    key voter_set, provider;
}</string>
                            </entry>
                            <entry key="nm_api/module.rell">
                                <string>module;

import common.*;
import model.*;

/*
    NM API

    Version 1: Initial Managed Mode support
    Version 2: MustSyncUntil feature
    Version 3: Containers and Clusters
    Version 4: Blockchain.system property added (chain0, anchoring_chain are system chains)
    Version 5: Precise Configuration Update
    Version 6: Blockchain states
    Version 7: nm_get_management_chain() added
    Version 8: Blockchain Configuration Options
*/

struct blockchain_info {
    rid: byte_array;
    system: boolean;
    state: blockchain_state;
}
</string>
                            </entry>
                            <entry key="nm_api/nm_api.rell">
                                <string>/*
    Returns NM API Version
    NM API Version: 1
*/
query nm_api_version() = 8;

/*
    Returns version of peerlist
    NM API Version: 1
    Deprecated since version 5:  is not relevant for multi-cluster environment
*/
query nm_get_peer_list_version() = node_list.last_update;

/*
    Returns peer info list
    NM API Version: 1
    (API expects array, so we need suppress naming)
*/
query nm_get_peer_infos(): list&lt;(text, integer, pubkey, timestamp)&gt; {
    val peer_infos = list&lt;(text, integer, pubkey, timestamp)&gt;();
    peer_infos.add_all(node @* {} (_ = .host, _ = .port, _ = .pubkey, _ = .last_updated));
    peer_infos.add_all(foreign_blockchain_import @* {} (_ = .host, _ = .port, _ = .pubkey, _ = 0));
    return peer_infos;
}

/*
    Configuration updates are found in two tables. Both must be checked to get next configuration height.
    NM API Version: 1
*/
query nm_find_next_configuration_height(blockchain_rid: byte_array, height: integer): integer? {
    val bc = blockchain @? { blockchain_rid };
    if (bc == null) return null;
    val conf_h = blockchain_configuration @? { bc, .height &gt; height } (@sort .height) limit 1;
    val sign_h = blockchain_configuration_signers @? { bc, .height &gt; height } (@sort .height) limit 1;
    if (conf_h == null) return sign_h;
    if (sign_h == null) return conf_h;
    return min(conf_h, sign_h);
}

/*
    Merge content of blockchain_configuration and blockchain_configuration_signers
    NM API Version: 1
*/
query nm_get_blockchain_configuration(blockchain_rid: byte_array, height: integer): byte_array? {
    val config = get_blockchain_configuration(blockchain_rid, height);
    if (config != null) {
        val full_config = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config.base_config));
        full_config["signers"] = config.signers.to_gtv();
        return full_config.to_gtv().to_bytes();
    } else {
        return null;
    }
}

/*
    NM API Version: 5
*/
query nm_get_blockchain_configuration_v5(blockchain_rid: byte_array, height: integer):
    (base_config: byte_array, signers: list&lt;pubkey&gt;, config_hash: byte_array)?
        = get_blockchain_configuration(blockchain_rid, height);

/*
    Returns list of blockchains to be launched
    NM API Version: 1 (Deprecated: Use nm_compute_blockchain_info_list)
*/
query nm_compute_blockchain_list(node_id: pubkey): list&lt;byte_array&gt; {
    val res = list&lt;byte_array&gt;();
    for (blockchain in compute_blockchain_info_list(node_id)) {
        res.add(blockchain.rid);
    }
    return res;
}

/*
    Returns list of blockchains to be launched
    NM API Version: 4
*/
query nm_compute_blockchain_info_list(node_id: pubkey): list&lt;blockchain_info&gt; {
    return compute_blockchain_info_list(node_id);
}

function compute_blockchain_info_list(node_id: pubkey): list&lt;blockchain_info&gt; {
    val node = node @? { node_id };
    if (exists(node)) {
        val res = set&lt;blockchain_info&gt;();
        res.add_all(get_cluster_node_blockchains(node));
        res.add_all(get_cluster_replica_node_blockchains(node));
        res.add_all(get_blockchains_replicated_by_node(node));
        return list(res);
    } else {
        return [blockchain_info(chain_context.blockchain_rid, true, blockchain_state.RUNNING)];
    }
}

/*
    NM API Version: 4
*/
query nm_get_blockchain_replica_node_map(blockchain_rids: set&lt;byte_array&gt;): map&lt;byte_array, set&lt;byte_array&gt;&gt; {
    val res = map&lt;byte_array, set&lt;byte_array&gt;&gt;();
    for (brid in set(blockchain_rids)) {
        res.put(brid, get_blockchain_replica_nodes(brid));
    }
    return res;
}

/*
    NM API Version: 3
*/
query nm_get_container_limits(name): map&lt;text, integer&gt; {
    require_container(name);

    var return_map = map&lt;text, integer&gt;();

    val container_limits = get_current_container_resource_limits(name);

    val container_units = container_limits[container_resource_limit_type.container_units];
    val max_blockchains = container_limits[container_resource_limit_type.max_blockchains];

    val cpu = _get_container_limit_or_default(standard_container_unit.cpu, container_units);
    val ram = _get_container_limit_or_default(standard_container_unit.ram, container_units);
    val io_read = _get_container_limit_or_default(standard_container_unit.io_read, container_units);
    val io_write = _get_container_limit_or_default(standard_container_unit.io_write, container_units);
    val storage = _get_container_limit_or_default(standard_container_unit.storage, container_units);

    return_map.put(container_resource_limit_type.container_units.name, container_units);
    return_map.put(container_resource_limit_type.max_blockchains.name, max_blockchains);
    return_map.put("storage", storage);
    return_map.put("cpu", cpu);
    return_map.put("ram", ram);
    return_map.put("io_read", io_read);
    return_map.put("io_write", io_write);

    return return_map;
}

function _get_container_limit_or_default(value: integer, container_units: integer): integer {
    return if (container_units == -1 or value == -1) -1 else container_units * value;
}

/*
    Returns node containers
    NM API Version: 3
*/
query nm_get_containers(pubkey): list&lt;text&gt; {
    val n = require(node @? { pubkey }, "Node with pubkey %s not found".format(pubkey));
    val clusters = cluster_node @* { n } .cluster;
    val res = list&lt;text&gt;();
    for (cl in clusters) {
        val containers = container @* { cl } .name;
        res.add_all(containers);
    }
    return res;
}

/*
    NM API Version: 3
*/
query nm_get_blockchains_for_container(container_name: text): list&lt;byte_array&gt; {
    val container = container @? {container_name};
    val res = list&lt;byte_array&gt;();
    if (exists(container)) {
        val cluster = container.cluster;
        res.add_all(container_blockchain @* {container, .blockchain.state in [blockchain_state.RUNNING, blockchain_state.PAUSED]} .blockchain.rid);
    }
    return res;
}

/*
    NM API Version: 3
*/
query nm_get_container_for_blockchain(blockchain_rid: byte_array): text {
    val bc = require_blockchain(blockchain_rid);
    return container_blockchain @ { bc } .container.name;
}

/*
    Returns a list of brids with corresponding container that this blockchain is dependent on. At the given height.
    NM API Version: 3
*/
query nm_get_blockchain_dependencies(blockchain, height: integer): list&lt;(byte_array, text)&gt; {
    val res = list&lt;(byte_array, text)&gt;();
    val conf_h = blockchain_configuration @? { blockchain, .height &lt;= height } (@sort .height) limit 1;
    if (conf_h != null) {
        val brids = blockchain_dependency @* {.me == blockchain, conf_h} .dependent_on.rid;
        for (brid in brids) {
            res.add((brid, container_blockchain @ { blockchain @{brid}} .container.name));
        }
    }
    return res;
}

/*
    Precise Configuration Update: Returns list of pending configs with minimum_height &lt;= height
    NM API Version: 5
*/
query nm_get_pending_blockchain_configuration(blockchain_rid: byte_array, height: integer):
        list&lt;(base_config: byte_array, signers: list&lt;pubkey&gt;, minimum_height: integer)&gt; {
    val bc = require_blockchain(blockchain_rid);
    return pending_blockchain_configuration @* { bc, .minimum_height &lt;= height } (
        base_config = .base_config,
        signers = list&lt;pubkey&gt;.from_gtv(gtv.from_bytes(.signers)),
        @sort minimum_height = .minimum_height
    );
}

/*
    Precise Configuration Update: Returns a pending blockchain config by config hash or null
    NM API Version: 5
*/
query nm_get_pending_blockchain_configuration_by_hash(blockchain_rid: byte_array, config_hash: byte_array):
        (base_config: byte_array, signers: list&lt;pubkey&gt;, minimum_height: integer)? {
    val bc = require_blockchain(blockchain_rid, include_removed = true);
    return pending_blockchain_configuration @? { bc, config_hash } (
        base_config = .base_config,
        signers = list&lt;pubkey&gt;.from_gtv(gtv.from_bytes(.signers)),
        @sort minimum_height = .minimum_height
    );
}

/*
    Precise Configuration Update: Returns a faulty blockchain config by height or null
    NM API Version: 5
*/
query nm_get_faulty_blockchain_configuration(blockchain_rid: byte_array, height: integer): byte_array? {
    val bc = require_blockchain(blockchain_rid);
    return faulty_blockchain_configuration @? { bc, .reported_at_height == height }.config_hash;
}

/*
    Returns current state of blockchain
    NM API Version: 6
*/
query nm_get_blockchain_state(blockchain_rid: byte_array): text {
    val bc = require_blockchain(blockchain_rid, false, true);
    return bc.state.name;
}

/*
    Returns Blockchain RID of management chain
    NM API Version: 7
*/
query nm_get_management_chain() = blockchain @ { blockchains.directory_chain } (.rid);

/*
    Returns blockchain_configuration_options structure for given blockchain and height or null
    NM API Version 8
*/
query nm_get_blockchain_configuration_options(blockchain_rid: byte_array, height: integer)
    = blockchain_configuration_options @? { .blockchain.rid == blockchain_rid, .height &lt;= height }
        (@omit @sort_desc .height, $.to_struct()) limit 1;
</string>
                            </entry>
                            <entry key="nm_api/nm_api_impl.rell">
                                <string>function get_cluster_node_blockchains(node): set&lt;blockchain_info&gt; {
    val blockchains = set(
        (cluster_node, container_blockchain) @* {
            cluster_node.node == node,
            cluster_node.cluster == container_blockchain.container.cluster,
            container_blockchain.blockchain.state in [blockchain_state.RUNNING, blockchain_state.PAUSED]
        } ( blockchain_info(container_blockchain.blockchain.rid, container_blockchain.blockchain.system, container_blockchain.blockchain.state) )
    );

    blockchains.add_all(
        signer_excluded_from_pending_configuration @* { .pubkey == node.pubkey }
            ( blockchain_info(.blockchain.rid, .blockchain.system, .blockchain.state) )
    );

    return blockchains;
}

function get_cluster_replica_node_blockchains(node) = set(
    (cluster_replica_node, container_blockchain) @* {
        cluster_replica_node.node == node,
        cluster_replica_node.cluster == container_blockchain.container.cluster,
        container_blockchain.blockchain.state in [blockchain_state.RUNNING, blockchain_state.PAUSED]
    } ( blockchain_info(container_blockchain.blockchain.rid, container_blockchain.blockchain.system, container_blockchain.blockchain.state) )
);

function get_blockchains_replicated_by_node(node) = set(
    blockchain_replica_node @* { 
        node, .blockchain.state in [blockchain_state.RUNNING, blockchain_state.PAUSED] 
    } (blockchain_info(.blockchain.rid, .blockchain.system, .blockchain.state))
);

function get_blockchain_replica_nodes(blockchain_rid: byte_array): set&lt;byte_array&gt; {
    val replicas = set&lt;byte_array&gt;();

    // cluster_replica_node
    val replica_nodes = (crn: cluster_replica_node, cb: container_blockchain) @* {
        cb.blockchain.rid == blockchain_rid,
        cb.container.cluster == crn.cluster
    } (.node.pubkey);
    replicas.add_all(replica_nodes);

    // blockchain_replica_node
    replicas.add_all(blockchain_replica_node @* { .blockchain.rid == blockchain_rid } (.node.pubkey));

    return replicas;
}
</string>
                            </entry>
                            <entry key="proposal/module.rell">
                                <string>module;

import common.*;
import .voting.*;

enum proposal_type {
    configuration_at,
    configuration,
    bc,
    container_limits,
    cluster_limits,
    cluster_provider,
    cluster_remove,
    voter_set_update,
    provider_state,
    provider_is_system,
    provider_quota,
    provider_batch,
    blockchain_action,
    cluster_anchoring_configuration,
    container,
    container_remove,

    blockchain_import,
    configuration_import,
    finish_blockchain_import,

    foreign_blockchain_import,
    foreign_blockchain_blocks_import,
}

enum proposal_state {
    PENDING, APPROVED, REJECTED, REVOKED
}

entity proposal {
    index timestamp, proposal_type;
    proposed_by: provider;
    index voter_set;
    description: text = "";
    transaction = op_context.transaction;
    mutable state: proposal_state = proposal_state.PENDING;
}

operation revoke_proposal(my_pubkey: pubkey, proposal_rowid: rowid) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    val prop = proposal @? { proposal_rowid };
    require(exists(prop), "Proposal not found: %d".format(proposal_rowid));
    require(prop!!.proposed_by == me, "It is only allowed to revoke own proposals");
    delete_proposal(prop, proposal_state.REVOKED);
}

function delete_proposal(prop: proposal, state: proposal_state) {
    delete_proposal_handlers()[prop.proposal_type.name](prop);
    prop.state = state;
}

@extendable function delete_proposal_handlers(): map&lt;text, (proposal) -&gt; unit&gt;;</string>
                            </entry>
                            <entry key="proposal/queries.rell">
                                <string>query get_proposals_range(from: timestamp, until: timestamp, only_pending: boolean) {
    return proposal @* {
        .timestamp &gt;= from,
        .timestamp &lt;= until,
        not(only_pending) or .state == proposal_state.PENDING
    } (.rowid, .proposal_type, .state);
}

query get_relevant_proposals(from: timestamp, until: timestamp, only_pending: boolean, my_pubkey: pubkey) {
    return (proposal, voter_set_member) @* {
        voter_set_member.voter_set == proposal.voter_set,
        voter_set_member.provider.pubkey == my_pubkey,
        proposal.timestamp &gt;= from,
        proposal.timestamp &lt;= until,
        not(only_pending) or proposal.state == proposal_state.PENDING
    } (proposal.rowid, proposal.proposal_type, proposal.state);
}

query get_proposal(id: rowid?): (id: rowid, timestamp: integer, type: proposal_type, proposed_by: pubkey, description: text, state: proposal_state)? {
    val result = if (id == null) proposal @? {} (@sort_desc @omit .rowid, $) limit 1 else proposal @? { id };
    if (result == null) return null;
    return (
        id = result.rowid,
        timestamp = result.timestamp,
        type = result.proposal_type,
        proposed_by = result.proposed_by.pubkey,
        description = result.description,
        state = result.state
    );
}

function require_proposal(rowid) = require(proposal @? { rowid }, "Proposal " + rowid + " not found");

function get_latest_proposal(rowid?, proposal_type) = if (rowid == null) proposal @ { proposal_type, proposal_state.PENDING } ( @max proposal ) else proposal @ { rowid };

struct proposal_voting_results {
    positive_votes: integer;
    negative_votes: integer;
    max_votes: integer;
    threshold: integer;
    voting_result;
}

query get_proposal_voting_results(rowid): proposal_voting_results {
    val proposal = require_proposal(rowid);
    require(proposal.state == proposal_state.PENDING, "This proposal is closed as %s. For info about voting use get_proposal_voter_info query.".format(proposal.state));
    val positive_votes = positive_votes(proposal);
    val negative_votes = negative_votes(proposal);
    val max_votes = max_votes(proposal.voter_set);
    val threshold = proposal.voter_set.threshold;
    val status = _compute_voting_result(positive_votes, negative_votes, max_votes, threshold);
    return proposal_voting_results(positive_votes, negative_votes, max_votes, threshold, status);
}

struct proposal_voter {
    provider: byte_array;
    provider_name: text;
    vote: boolean;
}

query get_proposal_voter_info(rowid): list&lt;proposal_voter&gt; {
    val proposal = require_proposal(rowid);
    return vote @* { .proposal.rowid == rowid } (proposal_voter(.provider.pubkey, .provider.name, .vote));
}
</string>
                            </entry>
                            <entry key="proposal/voting/apply.rell">
                                <string>// NB: check authority before calling this function
function internal_vote(provider, proposal, vote: boolean) {
    require(voter_set_member @? { proposal.voter_set, provider }, provider.pubkey + " must be a member of the voter set");
    create vote(proposal, provider, vote);
    log("vote '%s' added for proposal %s".format(if (vote) "Yes" else "No", proposal_str(proposal)));
    try_to_apply_proposal(proposal);
}

function try_to_apply_proposal(prop: proposal) {
    val prop_str = proposal_str(prop);
    val results = get_proposal_voting_results(prop.rowid);
    when (results.voting_result) {
        pending -&gt; log("proposal is still under discussion:", prop_str);
        rejected -&gt; {
            log("proposal rejected:", prop_str);
            delete_proposal(prop, proposal_state.REJECTED);
        }
        approved -&gt; {
            log("proposal approved:", prop_str);
            apply_voting_result_handlers()[prop.proposal_type.name](prop);
            delete_proposal(prop, proposal_state.APPROVED);
        }
    }
}

@extendable function apply_voting_result_handlers(): map&lt;text, (proposal) -&gt; unit&gt;;

function proposal_str(prop: proposal) {
    return "%s:%d".format(prop.proposal_type, prop.rowid);
}</string>
                            </entry>
                            <entry key="proposal/voting/module.rell">
                                <string>module;

import ^.*;

entity vote {
    key proposal, provider;
    vote: boolean; // yes | no
}

function create_voter_set_internal(name, threshold: integer = 0, governor: voter_set? = null) {
    val vs = create voter_set(name, threshold);
    if (exists(governor)) {
        create voter_set_governance(voter_set = vs, governor = governor);
    } else {
        create voter_set_governance(voter_set = vs, governor = vs);
    }
    return vs;
}

/**
 * Governance semantics:
 * Anybody can create a new voter_set directly, but it consumes an action point.
 * voter_set can be updated. If voter_set_governance is defined, it will control voter set, otherwise, it is the voter set itself.
 **/
operation create_voter_set(my_pubkey: pubkey, name, threshold: integer, initials: list&lt;pubkey&gt;?, governor: text?) {
    require_is_provider_with_rate_limit(my_pubkey);
    val governor_set = if (governor != null) require_voter_set(governor) else null;
    val vs = create_voter_set_internal(name, threshold, governor_set);
    if (exists(initials)) {
        for (prov in initials) {
            val p = require_provider(prov);
            require(roles.has_node_access(p), "Provider must have node access role to be part of a voter set");
            create voter_set_member(voter_set = vs, p);
        }
    }
}

operation make_vote(my_pubkey: pubkey, proposal_id: integer, vote: boolean) {
    require_is_signer(my_pubkey);
    val provider = require_provider(my_pubkey);
    val prop = require_proposal(rowid(proposal_id));
    require(prop.state == proposal_state.PENDING, "The proposal is already closed as %s".format(prop.state));
    require_voter_set_member(prop.voter_set, provider);
    require(empty(vote @? {prop, provider}), "Only one vote per pubkey is allowed");
    internal_vote(provider, prop, vote);
}

operation retract_vote(my_pubkey: pubkey, proposal_id: integer) {
    require_is_signer(my_pubkey);
    val provider = require_provider(my_pubkey);
    val prop = require_proposal(rowid(proposal_id));
    require(prop.state == proposal_state.PENDING, "The proposal is already closed as %s".format(prop.state));
    require_voter_set_member(prop.voter_set, provider);

    if (exists(vote @? { prop, provider })) {
        delete vote @* { prop, provider };
        log("vote for proposal retracted:", proposal_str(prop));
        try_to_apply_proposal(prop);
    } else {
        log("no vote for proposal to retract:", proposal_str(prop));
    }
}
</string>
                            </entry>
                            <entry key="proposal/voting/queries.rell">
                                <string>query get_provider_votes(from: timestamp, until: timestamp, provider_key: pubkey) {
    return (proposal, vote) @* {
        vote.provider.pubkey == provider_key,
        vote.proposal == proposal,
        proposal.timestamp &gt;= from,
        proposal.timestamp &lt;= until
    } ( .proposal, .vote );
}</string>
                            </entry>
                            <entry key="proposal/voting/vote.rell">
                                <string>enum voting_result {
    pending,
    approved,
    rejected
}

function positive_votes(proposal) = vote @? { proposal, .vote == true } (@sum 1) ?: 0;
function negative_votes(proposal) = vote @? { proposal, .vote == false } (@sum 1) ?: 0;
function max_votes(voter_set) = voter_set_member @ { voter_set } (@sum 1);

function _compute_voting_result(yes: integer, no: integer, max: integer, threshold: integer): voting_result {
    require (threshold &gt;= -1 and threshold &lt;= max, "Invalid threshold, must be in range [%d, %d] but was: %d".format(-1, max, threshold));
    require (yes + no &lt;= max, "Too many votes");
    when (threshold) {
        -1 -&gt; return _compute_voting_result_majority(yes, no, max);
        0 -&gt; return _compute_voting_result_super_majority(yes, no, max);
        else -&gt; return _compute_voting_result_custom(yes, no, max, threshold);
    }
}

function _compute_voting_result_custom(yes: integer, no: integer, max: integer, threshold: integer): voting_result {
    return _voting_result(yes, no, max, threshold);
}

function _compute_voting_result_majority(yes: integer, no: integer, max: integer): voting_result {
    val required = max / 2 + 1;
    return _voting_result(yes, no, max, required);
}

function _compute_voting_result_super_majority(yes: integer, no: integer, max: integer): voting_result {
    val required = max - (max - 1) / 3;
    return _voting_result(yes, no, max, required);
}

function _voting_result(yes: integer, no: integer, max: integer, required: integer): voting_result {
    log("Votes - positive: %d, negative: %d, required: %d, maximum: %d".format(yes, no, required, max));
    return when {
        yes &gt;= required -&gt; voting_result.approved;
        no &gt; max - required -&gt; voting_result.rejected;
        else -&gt; voting_result.pending;
    };
}</string>
                            </entry>
                            <entry key="proposal_blockchain/module.rell">
                                <string>module;

import common.*;
import proposal.*;
import model.*;
import .util.*;</string>
                            </entry>
                            <entry key="proposal_blockchain/proposal_blockchain.rell">
                                <string>// Proposed bc:s are put here while waiting for enough positive votes.
entity pending_blockchain {
    key proposal;
    name;
    data: byte_array;
    container;
}

entity added_blockchain {
    key proposal;
    blockchain;
}

@extend(is_container_available_for_removal) function(container) = 
        if (exists(pending_blockchain @* { container }))
            "Container %s has pending proposals and can't be deleted. Resolve proposals first".format(container.name)
        else null;

/*
 * Proposes a new blockchain to a container.
 * NB: only the deployer voter set of the container can do this.
 */
operation propose_blockchain(my_pubkey: pubkey, config_data: byte_array, bc_name: text, container_name: text, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val container = require_container(container_name);
    require_container_deployer(container, me);
    require(not container.system, "Proposing blockchain to a system container is not allowed");

    validate_blockchain_configuration(config_data, signers = true, header_hash = true);

    // Require container resource limits are honored
    require_container_is_not_full(container);

    require(empty(pending_blockchain @* { .data == config_data, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    val prop = create proposal(op_context.last_block_time, proposal_type.bc, me, container.deployer, description);
    create pending_blockchain(prop, bc_name, data = config_data, container);
    internal_vote(me, prop, true);
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.bc.name: delete_pending_blockchain(*)];

function delete_pending_blockchain(proposal) {
    delete pending_blockchain @? { proposal };
}

@extend(apply_voting_result_handlers) function() = [proposal_type.bc.name: apply_blockchain_proposal(*)];

// Initial signers of new bc are the ones in cluster_node table.
function apply_blockchain_proposal(proposal) {
    val bc = pending_blockchain @? {proposal};
    if (bc == null) return;
    val nodes = cluster_node @* { bc.container.cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(nodes.size() &gt; 0, "Cluster must have at least one node");
    require_container_is_not_full(bc.container);

    val blockchain = add_blockchain(bc.data, nodes, bc.name, bc.container);
    create added_blockchain(proposal, blockchain);
    log("Added blockchain", blockchain.rid);
}

query get_blockchain_proposal(rowid): (data:byte_array, container:text)? {
    return pending_blockchain @? { require_proposal(rowid) } ( data = .data, container = .container.name );
}

/**
 * tx_rid: transaction rid of blockchain proposal
 * returns blockchain RID, or null if proposal is not applied
 */
query find_blockchain_rid(tx_rid: byte_array): byte_array? { 
    val proposal = require(proposal @? { proposal_type.bc, .transaction.tx_rid == tx_rid }, "No blockchain proposal found in given transaction");
    return added_blockchain @? { proposal }.blockchain.rid;
}
</string>
                            </entry>
                            <entry key="proposal_blockchain/proposal_blockchain_action.rell">
                                <string>enum blockchain_action {
    pause,
    resume,
    remove
}

entity pending_blockchain_action {
    key proposal;
    key blockchain;
    action: blockchain_action;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.blockchain_action.name: apply_blockchain_action(*)];

function apply_blockchain_action(proposal) {
    val pba = pending_blockchain_action @? { proposal };
    if (pba == null) return;
    when (pba.action) {
        pause -&gt; _apply_pause_blockchain(pba, proposal);
        resume -&gt; _apply_resume_blockchain(pba, proposal);
        remove -&gt; _apply_delete_blockchain(pba, proposal);
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.blockchain_action.name: delete_pending_blockchain_action(*)];

function delete_pending_blockchain_action(proposal) {
    delete pending_blockchain_action @? { proposal };
}

// Stop block production by inactivating bc, and keep replicas.
function _apply_pause_blockchain(action: pending_blockchain_action, proposal) {
    update blockchain @ { action.blockchain.rid } (.state = blockchain_state.PAUSED);
    // Keep replicas
    for (signer in get_blockchain_signer_nodes(action.blockchain)) {
        create blockchain_replica_node(action.blockchain, signer);
    }
}

// Restart block production; block builders will be the ones in cluster_node.
function _apply_resume_blockchain(action: pending_blockchain_action, proposal) {
    update blockchain @ { action.blockchain.rid } (.state = blockchain_state.RUNNING);
    // Removing replicas if they are cluster nodes
    val nodes = get_blockchain_signer_nodes(action.blockchain);
    for (node_info in nodes) {
        delete blockchain_replica_node @? { action.blockchain, node_info };
    }
}

// Delete everything about this bc except D1 information
function _apply_delete_blockchain(action: pending_blockchain_action, proposal) {
    val bc = action.blockchain;
    before_delete_blockchain(bc);
    bc.state = blockchain_state.REMOVED;
    delete container_blockchain @ { bc };
    delete blockchain_replica_node @* { bc };
    delete pending_blockchain_action @ { proposal };
    delete blockchain_dependency @* { .me == bc };
}

operation propose_blockchain_action(my_pubkey: pubkey, blockchain_rid: byte_array, action: blockchain_action, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain(blockchain_rid);
    val container = container_blockchain @ {blockchain} .container;
    require_container_deployer(container, me);
    if (action == blockchain_action.remove) 
        require_no_dependencies_on_me(blockchain);
    else
        require(blockchain.state != blockchain_state.REMOVED, "Removed blockchain can not be revived");
    val prop = create proposal(op_context.last_block_time, proposal_type.blockchain_action, me, container.deployer, description);
    create pending_blockchain_action(prop, blockchain, action);
    internal_vote(me, prop, true);
}

query get_blockchain_action_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.blockchain_action);
    if (proposal == null) return null;
    val pba = pending_blockchain_action @ { proposal };
    return (
        blockchain = pba.blockchain.rid,
        blockchain_name = pba.blockchain.name,
        action = pba.action
    );
}</string>
                            </entry>
                            <entry key="proposal_blockchain/proposal_configuration.rell">
                                <string>entity pending_configuration {
    key proposal;
    blockchain;
    data: byte_array;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.configuration.name: apply_configuration(*)];

function apply_configuration(proposal) {
    val pc = pending_configuration @? { proposal };
    if (pc == null) return;
    val is_chain0 = pc.blockchain.rid == chain_context.blockchain_rid;

    if (is_chain0) {
        apply_configuration_chain0(pc);
    } else {
        apply_configuration_regular(pc);
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.configuration.name: delete_pending_configuration(*)];

function delete_pending_configuration(proposal) {
    delete pending_configuration @? { proposal };
}

function apply_configuration_chain0(pc: pending_configuration) {
    val apply_at_height = op_context.block_height + 1; // NB: compute_blockchain_info_list()/get_cluster_node_blockchains() relies on this
    log("Base configuration update chain0 at height %d".format(apply_at_height));
    require(empty(blockchain_configuration @? { pc.blockchain, apply_at_height }), "Configuration at height %d already exists".format(apply_at_height));
    val unique_base_config = make_config_unique(pc.data);
    create blockchain_configuration(pc.blockchain, apply_at_height, unique_base_config);
    add_dependencies(unique_base_config, pc.blockchain.rid, apply_at_height);
}

function apply_configuration_regular(pc: pending_configuration) {
    val last_configuration_height = (blockchain_configuration @? { pc.blockchain } (@sort_desc .height) limit 1) ?: 0;
    val last_pending_configuration = pending_blockchain_configuration @? { pc.blockchain } (@sort_desc @omit .minimum_height, $) limit 1;
    val (minimum_height, signers) = if (last_pending_configuration != null)
        (last_configuration_height.max(last_pending_configuration.minimum_height) + 1,
         last_pending_configuration.signers)
     else
        (last_configuration_height + 1,
         blockchain_configuration_signers @ { pc.blockchain } (@omit @sort_desc .height, .signers) limit 1);
    log("Base configuration update for chain %s at minimum height %d".format(pc.blockchain.rid, minimum_height));
    val unique_base_config = make_config_unique(pc.data);
    create pending_blockchain_configuration(
        pc.blockchain,
        minimum_height,
        config_hash = calculate_configuration_hash(unique_base_config, list&lt;byte_array&gt;.from_gtv(gtv.from_bytes(signers))),
        base_config = unique_base_config,
        signers
    );
}

operation propose_configuration(my_pubkey: pubkey, blockchain_rid: byte_array, config_data: byte_array, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain(blockchain_rid);
    val container = container_blockchain @ {blockchain} .container;
    require_container_deployer(container, me);
    val is_chain0 = blockchain.rid == chain_context.blockchain_rid;

    validate_blockchain_configuration(config_data, signers = not is_chain0, header_hash = not is_chain0);

    val prop = create proposal(op_context.last_block_time, proposal_type.configuration, me, container.deployer, description);
    create pending_configuration(prop, blockchain, config_data);
    internal_vote(me, prop, true);
}

query get_configuration_proposal(rowid?): (
    current_conf:struct&lt;blockchain_configuration&gt;,
    proposed_conf:struct&lt;pending_configuration&gt;
)? {
    val proposal = get_latest_proposal(rowid, proposal_type.configuration);
    if (proposal == null) return null;
    val config = pending_configuration @? { require_proposal(proposal.rowid) };
    if (config == null) return null;

    val current = (blockchain_configuration @ { config.blockchain }
     (@omit @sort_desc .height, $) limit 1);

    return (
        current_conf = current.to_struct(),
        proposed_conf = config.to_struct()
    );
}</string>
                            </entry>
                            <entry key="proposal_blockchain/proposal_configuration_at.rell">
                                <string>entity pending_configuration_at {
    key proposal;
    blockchain;
    height: integer;
    force: boolean;
    data: byte_array;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.configuration_at.name: apply_configuration_at(*)];

function apply_configuration_at(proposal) {
    val pc = pending_configuration_at @? { proposal };
    if (pc == null) return;

    require(pc.height &gt;=0, "height must be &gt;= 0");
    require(empty(blockchain_configuration @? { pc.blockchain, pc.height } limit 1) or pc.force, "Configuration at height %d already exists for blockchain %s, need to set force to override".format(pc.height, pc.blockchain.rid));

    val height = pc.height;

    val is_chain0 = pc.blockchain.rid == chain_context.blockchain_rid;
    val config_data = if (not is_chain0) make_config_unique(pc.data) else pc.data;
    if (not(exists(blockchain_configuration @? { pc.blockchain, height }))) {
        create blockchain_configuration(pc.blockchain, height, data = config_data);
        add_dependencies(config_data, pc.blockchain.rid, height);
    } else {
        update blockchain_configuration @ { pc.blockchain, height } ( .data = config_data );
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.configuration_at.name: delete_pending_configuration_at(*)];

function delete_pending_configuration_at(proposal) {
    delete pending_configuration_at @? { proposal };
}

/*
 * Proposes a new configuration for a blockchain.
 * NB: Only the deployer of the container the blockchain is running in can perform operation
 */
operation propose_configuration_at(my_pubkey: pubkey, blockchain_rid: byte_array, config_data: byte_array, height: integer, force: boolean, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain(blockchain_rid);
    val container = container_blockchain @ { blockchain }.container;
    require_container_deployer(container, me);
    val is_chain0 = blockchain.rid == chain_context.blockchain_rid or
        chain_context.blockchain_rid == x"0000000000000000000000000000000000000000000000000000000000000000"; // for unit tests
    require(is_chain0, "Proposing configuration at a specific height disallowed for chain: " + blockchain_rid);
    validate_blockchain_configuration(config_data, signers = not is_chain0, header_hash = false);

    require(height &gt;= 0, "height must be &gt;= 0");
    require(empty(blockchain_configuration @? { blockchain, height } limit 1) or force, "Configuration at height %d already exists for blockchain %s, need to set force to override".format(height, blockchain.rid));

    val pending_config = pending_configuration_at @? { blockchain, height, .proposal.state == proposal_state.PENDING } limit 1;
    require(empty(pending_config),
        "Pending configuration proposal already exists: blockchain_rid: %s, height: %d. Revoke the proposal %d first."
            .format(blockchain.rid, height, pending_config?.proposal)
    );

    val prop = create proposal(op_context.last_block_time, proposal_type.configuration_at, me, container.deployer, description);
    create pending_configuration_at(prop, blockchain, height, force, data = config_data);
    internal_vote(me, prop, true);
}

query get_configuration_proposal_at(rowid?): (
    current_conf: struct&lt;blockchain_configuration&gt;,
    proposed_conf: struct&lt;pending_configuration_at&gt;
)? {
    val proposal = get_latest_proposal(rowid, proposal_type.configuration_at);
    if (proposal == null) return null;
    val config = pending_configuration_at @? { require_proposal(proposal.rowid) };
    if (config == null) return null;
    val current = blockchain_configuration @ { config.blockchain, .height &lt; config.height }
    (@omit @sort_desc .height, $) limit 1;

    return (
        current_conf = current.to_struct(),
        proposed_conf = config.to_struct()
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain/util/module.rell">
                                <string>module;

import model.*;
import common.*;

function validate_blockchain_configuration(config_data: byte_array, signers: boolean, header_hash: boolean) {
    val config_map = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data));
    if (signers) {
        require("signers" not in config_map, "Configuration must not contain \"signers\"");
    }
    if (header_hash) {
        require("config_consensus_strategy" in config_map,
            "Configuration must contain \"config_consensus_strategy\"=\"HEADER_HASH\"");
        require(config_map["config_consensus_strategy"] == "HEADER_HASH".to_gtv(),
            "Configuration must contain \"config_consensus_strategy\"=\"HEADER_HASH\"");
    }
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/module.rell">
                                <string>module;

import common.*;
import proposal.*;
import model.*;
import .util.*;</string>
                            </entry>
                            <entry key="proposal_blockchain_import/proposal_blockchain_import.rell">
                                <string>entity pending_blockchain_import {
    key proposal;
    name;
    blockchain_rid: byte_array;
    config_data: byte_array;
    container;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.blockchain_import.name: apply_blockchain_import(*)];
@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.blockchain_import.name: delete_pending_blockchain_import(*)];

operation propose_import_blockchain(my_pubkey: pubkey, config_data: byte_array, blockchain_rid: byte_array, bc_name: text, container_name: text,
                                    description: text = "Propose import blockchain") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val container = require_container(container_name);
    require_container_deployer(container, me);

    require(empty(blockchain @? { blockchain_rid }), "Blockchain with RID %s already exists".format(blockchain_rid));

    require("signers" in map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data)), "No signers in configuration");

    // Require container resource limits are honored
    require_container_is_not_full(container);

    require(empty(pending_blockchain_import @* { .blockchain_rid == blockchain_rid, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    val prop = create proposal(op_context.last_block_time, proposal_type.blockchain_import, me, container.deployer, description);
    create pending_blockchain_import(prop, bc_name, blockchain_rid, config_data, container);
    internal_vote(me, prop, true);
}

function apply_blockchain_import(proposal) {
    val pbi = pending_blockchain_import @? { proposal };
    if (pbi == null) return;

    require(empty(blockchain @? { pbi.blockchain_rid }), "Blockchain with RID %s already exists".format(pbi.blockchain_rid));

    val nodes = cluster_node @* { pbi.container.cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(nodes.size() &gt; 0, "Cluster must have at least one node");
    require_container_is_not_full(pbi.container);        

    val blockchain = create blockchain(pbi.blockchain_rid, pbi.name, system = false, state = blockchain_state.IMPORTING);
    create container_blockchain(pbi.container, blockchain);

    add_configuration_with_signers(blockchain, 0, pbi.config_data);

    log("Blockchain import started: %s / %s".format(pbi.name, pbi.blockchain_rid));
}

function delete_pending_blockchain_import(proposal) {
    delete pending_blockchain_import @? { proposal };
}

query get_blockchain_import_proposal(rowid?):
    (name: text, blockchain_rid: byte_array, config_data: byte_array, container: text)?
{
    val proposal = get_latest_proposal(rowid, proposal_type.blockchain_import);
    if (proposal == null) return null;
    return pending_blockchain_import @ { proposal } (
        name = .name,
        blockchain_rid = .blockchain_rid,
        config_data = .config_data,
        container = .container.name
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/proposal_configuration_import.rell">
                                <string>entity pending_configuration_import {
    key proposal;
    blockchain;
    height: integer;
    config_data: byte_array;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.configuration_import.name: apply_configuration_import(*)];
@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.configuration_import.name: delete_pending_configuration_import(*)];

operation propose_import_configuration(my_pubkey: pubkey, blockchain_rid: byte_array, height: integer, config_data: byte_array,
                                       description: text = "Propose import configuration") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain_entity(blockchain_rid);
    require(blockchain.state == blockchain_state.IMPORTING, "Blockchain must be in %s state to import configurations".format(blockchain_state.IMPORTING));

    val container = container_blockchain @ { blockchain }.container;
    require_container_deployer(container, me);

    require(empty(blockchain_configuration @? { blockchain, height } limit 1), 
        "Configuration at height %d already exists for blockchain %s".format(height, blockchain.rid));
    require("signers" in map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data)), "No signers in configuration");

    require(empty(pending_configuration_import @* { blockchain, .height == height, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    val prop = create proposal(op_context.last_block_time, proposal_type.configuration_import, me, container.deployer, description);
    create pending_configuration_import(prop, blockchain, height, config_data);
    internal_vote(me, prop, true);
}

function apply_configuration_import(proposal) {
    val pci = pending_configuration_import @? { proposal };
    if (pci == null) return;

    val container = container_blockchain @ { pci.blockchain }.container;
    val nodes = cluster_node @* { container.cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(nodes.size() &gt; 0, "Cluster must have at least one node");

    require(empty(blockchain_configuration @? { pci.blockchain, pci.height } limit 1), 
        "Configuration at height %d already exists for blockchain %s".format(pci.height, pci.blockchain.rid));

    add_configuration_with_signers(pci.blockchain, pci.height, pci.config_data);

    log("Configuration imported: %d / %s".format(pci.height, pci.blockchain.rid));
}

function delete_pending_configuration_import(proposal) {
    delete pending_configuration_import @? { proposal };
}

query get_configuration_import_proposal(rowid?):
    (blockchain_rid: byte_array, height: integer, config_data: byte_array)?
{
    val proposal = get_latest_proposal(rowid, proposal_type.configuration_import);
    if (proposal == null) return null;
    return pending_configuration_import @ { proposal } (
        blockchain_rid = .blockchain.rid,
        height = .height,
        config_data = .config_data
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/proposal_finish_blockchain_import.rell">
                                <string>entity pending_finish_blockchain_import {
    key proposal;
    blockchain: blockchain;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.finish_blockchain_import.name: apply_finish_blockchain_import(*)];
@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.finish_blockchain_import.name: delete_pending_finish_blockchain_import(*)];

operation propose_finish_import_blockchain(my_pubkey: pubkey, blockchain_rid: byte_array,
                                    description: text = "Propose finish import blockchain") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain_entity(blockchain_rid);
    require(blockchain.state == blockchain_state.IMPORTING, "Blockchain must be in %s state to finish import".format(blockchain_state.IMPORTING));

    val container = container_blockchain @ { blockchain }.container;
    require_container_deployer(container, me);

    require(empty(pending_finish_blockchain_import @* { blockchain, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    val prop = create proposal(op_context.last_block_time, proposal_type.finish_blockchain_import, me, container.deployer, description);
    create pending_finish_blockchain_import(prop, blockchain);
    internal_vote(me, prop, true);
}

function apply_finish_blockchain_import(proposal) {
    val pfbi = pending_finish_blockchain_import @? { proposal };
    if (pfbi == null) return;

    val container = container_blockchain @ { pfbi.blockchain }.container;
    val nodes = cluster_node @* { container.cluster } (@sort .node.pubkey);
    require(nodes.size() &gt; 0, "Cluster must have at least one node");

    update_configuration_signers_regular(pfbi.blockchain, nodes, null);
    update blockchain @ { pfbi.blockchain.rid } (.state = blockchain_state.RUNNING);

    log("Blockchain import finished: %s".format(pfbi.blockchain.rid));
}

function delete_pending_finish_blockchain_import(proposal) {
    delete pending_finish_blockchain_import @? { proposal };
}

query get_finish_blockchain_import_proposal(rowid?):
    (blockchain_rid: byte_array)?
{
    val proposal = get_latest_proposal(rowid, proposal_type.finish_blockchain_import);
    if (proposal == null) return null;
    return pending_finish_blockchain_import @ { proposal } (
        blockchain_rid = .blockchain.rid
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/proposal_foreign_blockchain_blocks_import.rell">
                                <string>entity pending_foreign_blockchain_blocks_import {
    key proposal;
    blockchain: blockchain;
    up_to_height: integer;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.foreign_blockchain_blocks_import.name: apply_foreign_blockchain_blocks_import(*)];
@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.foreign_blockchain_blocks_import.name: delete_pending_foreign_blockchain_blocks_import(*)];

operation propose_foreign_blockchain_blocks_import(
    my_pubkey: pubkey, blockchain_rid: byte_array, up_to_height: integer, description: text = "Propose import foreign blockchain blocks"
) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val blockchain = require_blockchain_entity(blockchain_rid);
    require(blockchain.state == blockchain_state.IMPORTING, "Blockchain must be in %s state to start importing blocks".format(blockchain_state.IMPORTING));

    val container = container_blockchain @ { blockchain }.container;
    require_container_deployer(container, me);

    require(exists(foreign_blockchain_import @* { blockchain_rid }), "Can't find foreign blockchain being imported: %s".format(blockchain_rid));
    require(empty(pending_foreign_blockchain_blocks_import @* { blockchain, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    require_up_to_height_is_less_or_equals_last_config_height(blockchain, up_to_height);

    val prop = create proposal(op_context.last_block_time, proposal_type.foreign_blockchain_blocks_import, me, container.deployer, description);
    create pending_foreign_blockchain_blocks_import(prop, blockchain, up_to_height);
    internal_vote(me, prop, true);
}

function apply_foreign_blockchain_blocks_import(proposal) {
    val pfbbi = pending_foreign_blockchain_blocks_import @? { proposal };
    if (pfbbi == null) return;

    val container = container_blockchain @ { pfbbi.blockchain }.container;
    val nodes = cluster_node @* { container.cluster } (@sort .node.pubkey);
    require(nodes.size() &gt; 0, "Cluster must have at least one node");
    require(exists(foreign_blockchain_import @* { .blockchain_rid == pfbbi.blockchain.rid }),
        "Can't find foreign blockchain being imported: %s".format(pfbbi.blockchain.rid));
    require_up_to_height_is_less_or_equals_last_config_height(pfbbi.blockchain, pfbbi.up_to_height);
    val fbi = require(foreign_blockchain_import @? { .blockchain_rid == pfbbi.blockchain.rid },
        "Can't find foreign blockchain being imported: %s".format(pfbbi.blockchain.rid)
    );
    require(pfbbi.up_to_height != -1,
        "A up_to_height (%s) already proposed for foreign blockchain import: %s".format(pfbbi.up_to_height, pfbbi.blockchain.rid)
    );

    update blockchain @ { pfbbi.blockchain.rid } (.state = blockchain_state.RUNNING);
    create blockchain_configuration_signers(pfbbi.blockchain, pfbbi.up_to_height + 1, nodes.to_gtv().to_bytes());
    fbi.up_to_height = pfbbi.up_to_height;
    create blockchain_configuration_options(
        pfbbi.blockchain, pfbbi.up_to_height + 1, suppress_special_transaction_validation = false
    );

    log("Foreign blockchain blocks import started: %s / %s".format(pfbbi.blockchain.name, pfbbi.blockchain.rid));
}

function delete_pending_foreign_blockchain_blocks_import(proposal) {
    delete pending_foreign_blockchain_blocks_import @? { proposal };
}

query get_foreign_blockchain_blocks_import_proposal(rowid?): (blockchain_rid: byte_array, up_to_height: integer)? {
    val proposal = get_latest_proposal(rowid, proposal_type.foreign_blockchain_blocks_import);
    if (proposal == null) return null;
    return pending_foreign_blockchain_blocks_import @ { proposal } (
        blockchain_rid = .blockchain.rid,
        up_to_height = .up_to_height
    );
}

function require_up_to_height_is_less_or_equals_last_config_height(blockchain, up_to_height: integer) {
    val last_config_height = require(blockchain_configuration @? { blockchain } (@sort_desc .height) limit 1,
        "No configurations found for importing blockchain: " + blockchain.rid
    );
    require(last_config_height &lt;= up_to_height,
        "Proposed up_to_height (%s) must be greater or equal to the height (%s) of the latest imported configuration: %s"
        .format(up_to_height, last_config_height, blockchain.rid)
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/proposal_foreign_blockchain_import.rell">
                                <string>entity pending_foreign_blockchain_import {
    key proposal;
    pubkey;
    host: text;
    port: integer;
    api_url: text;
    chain0_rid: byte_array;
    blockchain_name: text;
    blockchain_rid: byte_array;
    initial_config_data: byte_array;
    container;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.foreign_blockchain_import.name: apply_foreign_blockchain_import(*)];
@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.foreign_blockchain_import.name: delete_pending_foreign_blockchain_import(*)];

operation propose_foreign_blockchain_import(
    my_pubkey: pubkey,
    node_pubkey: pubkey,
    host: text,
    port: integer,
    api_url: text,
    chain0_rid: byte_array,
    blockchain_name: text,
    blockchain_rid: byte_array,
    initial_config_data: byte_array,
    container_name: text,
    description: text = "Propose import foreign blockchain"
) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val container = require_container(container_name);
    require_container_deployer(container, me);

    require(empty(blockchain @? { blockchain_rid }), "Blockchain with RID %s already exists".format(blockchain_rid));
    require("signers" in map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(initial_config_data)), "No signers in configuration");
    // Require container resource limits are honored
    require_container_is_not_full(container);
    require(empty(pending_foreign_blockchain_import @* { .blockchain_rid == blockchain_rid, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");

    val prop = create proposal(op_context.last_block_time, proposal_type.foreign_blockchain_import, me, container.deployer, description);
    create pending_foreign_blockchain_import(
        prop,
        pubkey = node_pubkey, host, port, api_url,
        chain0_rid,
        blockchain_name, blockchain_rid, initial_config_data,
        container);
    internal_vote(me, prop, true);
}

function apply_foreign_blockchain_import(proposal) {
    val pfbi = pending_foreign_blockchain_import @? { proposal };
    if (pfbi == null) return;

    require(empty(blockchain @? { pfbi.blockchain_rid }), "Blockchain with RID %s already exists".format(pfbi.blockchain_rid));

    val nodes = cluster_node @* { pfbi.container.cluster } (@sort .node.pubkey);
    require(nodes.size() &gt; 0, "Cluster must have at least one node");
    require_container_is_not_full(pfbi.container);

    val blockchain = create blockchain(pfbi.blockchain_rid, pfbi.blockchain_name, system = false, state = blockchain_state.IMPORTING);
    create container_blockchain(pfbi.container, blockchain);
    add_configuration_with_signers(blockchain, 0, pfbi.initial_config_data);
    create foreign_blockchain_import(
        pubkey = pfbi.pubkey,
        host = pfbi.host,
        port = pfbi.port,
        api_url = pfbi.api_url,
        chain0_rid = pfbi.chain0_rid,
        blockchain_rid = pfbi.blockchain_rid
    );
    create blockchain_configuration_options(
        blockchain, 0, suppress_special_transaction_validation = true
    );

    log("Foreign blockchain import started: %s / %s".format(pfbi.blockchain_name, pfbi.blockchain_rid));
}

function delete_pending_foreign_blockchain_import(proposal) {
    delete pending_foreign_blockchain_import @? { proposal };
}

query get_foreign_blockchain_import_proposal(rowid?) {
    val proposal = get_latest_proposal(rowid, proposal_type.blockchain_import);
    if (proposal == null) return null;
    return pending_foreign_blockchain_import @ { proposal } (
        foreign_node = .pubkey,
        host = .host,
        port = .port,
        api_url = .api_url,
        chain0_rid = .chain0_rid,
        blockchain_name = .blockchain_name,
        blockchain_rid = .blockchain_rid,
        container = .container.name
    );
}
</string>
                            </entry>
                            <entry key="proposal_blockchain_import/util/module.rell">
                                <string>module;

import model.*;
import common.*;

function add_configuration_with_signers(blockchain, height: integer, config_data: byte_array) {
    val config_map = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data));
    val signers = require(config_map.remove_or_null("signers"), "No signers in configuration");
    val base_config = config_map.to_gtv();

    create blockchain_configuration(blockchain, height, base_config.to_bytes());
    create blockchain_configuration_signers(blockchain, height, signers.to_bytes());
    add_dependencies(config_data, blockchain.rid, height);
}
</string>
                            </entry>
                            <entry key="proposal_cluster/module.rell">
                                <string>module;

import common.*;
import model.*;
import proposal.*;</string>
                            </entry>
                            <entry key="proposal_cluster/proposal_cluster_limits.rell">
                                <string>entity pending_cluster_limits {
    key proposal;
    key cluster;
    cluster_units: integer;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.cluster_limits.name: apply_cluster_limits(*)];

function apply_cluster_limits(proposal) {
    val pps = pending_cluster_limits @? { proposal };
    if (pps == null) return;
    pps.cluster.cluster_units = pps.cluster_units;
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.cluster_limits.name: delete_pending_cluster_limits(*)];

function delete_pending_cluster_limits(proposal) {
    delete pending_cluster_limits @? { proposal };
}

// The operation is mostly needed to make rell-maven-plugin generate code for enum `cluster_resource_limit_type`
operation propose_cluster_limits(my_pubkey: pubkey, cluster_name: text, cluster_units: integer? = null, description: text = "") {
    val me = require_provider(my_pubkey);
    // check that provider authority and that it is a cluster governor
    require_provider_auth_with_rate_limit(me);
    val cluster = require_cluster(cluster_name);
    require_cluster_governor(cluster, me);
    val new_cluster_units = if (cluster_units != null) cluster_units else cluster.cluster_units;
    _require_cluster_units(cluster, new_cluster_units);
    val prop = create proposal(op_context.last_block_time, proposal_type.cluster_limits, me, cluster.governance, description);
    create pending_cluster_limits(
        prop,
        cluster,
        cluster_units = new_cluster_units
    );
    internal_vote(me, prop, true);
}

query get_cluster_limits_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.cluster_limits);
    if (proposal == null) return null;
    val pcl = pending_cluster_limits @ { proposal };
    return (
        cluster = pcl.cluster.name,
        cluster_units = pcl.cluster_units
    );
}

function _require_cluster_units(cluster, new_cluster_units: integer) {
    require(new_cluster_units &gt; 0, "Cluster must consist of at least 1 cluster_unit");
    val minimum_cluster_units = get_minimum_cluster_units_for_current_container_units(cluster);
    require(new_cluster_units &gt;= minimum_cluster_units,
        "Can't propose cluster limits since cluster_units is too low for current usage of containers. Minimum cluster_units is %d".format(minimum_cluster_units));
    _require_new_cluster_units_for_current_nodes(cluster, new_cluster_units);
}

function _require_new_cluster_units_for_current_nodes(cluster, new_cluster_units: integer) {
    val needed_cluster_units = new_cluster_units - cluster.cluster_units;
    if (needed_cluster_units &gt; 0) {
        val nodes = set&lt;node&gt;();
        nodes.add_all(cluster_node @* { cluster }.node);
        nodes.add_all(cluster_replica_node @* { cluster }.node);
        val too_small_nodes = set&lt;pubkey&gt;();
        for (node in nodes) {
            if (get_available_cluster_units_for_node(node) &lt; needed_cluster_units) too_small_nodes.add(node.pubkey);
        }
        require(empty(too_small_nodes),
            "Can't propose cluster limits since nodes %s does not have room for another %d cluster_units".format(too_small_nodes.to_text(), needed_cluster_units));
    }
}
</string>
                            </entry>
                            <entry key="proposal_cluster/proposal_cluster_provider.rell">
                                <string>entity pending_cluster_provider {
    key proposal;
    key cluster;
    provider;
    add: boolean;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.cluster_provider.name: apply_cluster_provider(*)];

function apply_cluster_provider(proposal) {
    val pps = pending_cluster_provider @? {proposal};
    if (pps == null) return;
    if (pps.add) {
        create cluster_provider(pps.cluster, pps.provider);
    } else {
        delete cluster_provider @ {pps.cluster, pps.provider};
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.cluster_provider.name: delete_pending_cluster_provider(*)];

function delete_pending_cluster_provider(proposal) {
    delete pending_cluster_provider @? { proposal };
}

operation propose_cluster_provider(my_pubkey: pubkey, cluster_name: text, provider_pubkey: pubkey, add: boolean, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    val provider = require_provider(provider_pubkey);
    require_node_access(provider);
    // Check that provider authority and that it is a cluster governor
    val cluster = require_cluster(cluster_name);
    require(cluster.name != clusters.system, "Cannot add provider to system cluster manually");
    require_cluster_governor(cluster, me);
    val prop = create proposal(op_context.last_block_time, proposal_type.cluster_provider, me, cluster.governance, description);
    create pending_cluster_provider(prop, cluster, provider, add);
    internal_vote(me, prop, true);
}

query get_cluster_provider_proposal(rowid?) {
    val proposal = get_latest_proposal(rowid, proposal_type.cluster_provider);
    if (proposal == null) return null;
    val pcp = pending_cluster_provider @ { proposal };
    return (
        cluster = pcp.cluster.name,
        provider = pcp.provider.pubkey,
        add = pcp.add
    );
}
</string>
                            </entry>
                            <entry key="proposal_cluster/proposal_cluster_remove.rell">
                                <string>entity pending_remove_cluster {
    key proposal;
    key cluster;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.cluster_remove.name: apply_remove_cluster(*)];

function apply_remove_cluster(proposal) {
    val cl = pending_remove_cluster @? { proposal } .cluster;
    if (cl == null) return;
    delete pending_remove_cluster @ { proposal };
    remove_cluster_impl(cl);
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.cluster_remove.name: delete_pending_cluster_remove(*)];

function delete_pending_cluster_remove(proposal) {
    delete pending_remove_cluster @? { proposal };
}

operation propose_remove_cluster(my_pubkey: pubkey, name, description: text = "") {
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    val c = require(cluster @? { name }, "Unknown cluster %s".format(name));
    require_cluster_governor(c, me);
    require_cluster_available_for_removal(c);

    val prop = create proposal(op_context.last_block_time, proposal_type.cluster_remove, me, c.governance, description);
    create pending_remove_cluster(prop, c);
    internal_vote(me, prop, true);
}

query get_cluster_remove_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.cluster_remove);
    if (proposal == null) return null;
    return pending_remove_cluster @ { proposal } .cluster.name;
}</string>
                            </entry>
                            <entry key="proposal_cluster_anchoring/module.rell">
                                <string>module;

import proposal.*;
import model.*;
</string>
                            </entry>
                            <entry key="proposal_cluster_anchoring/proposal_cluster_anchoring.rell">
                                <string>entity pending_cluster_anchoring_configuration {
    key proposal;
    data: byte_array;  // map&lt;string, gtv&gt;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.cluster_anchoring_configuration.name: apply_cluster_anchoring_configuration(*)];

function apply_cluster_anchoring_configuration(proposal) {
    val pcac = pending_cluster_anchoring_configuration @? { proposal };
    if (pcac == null) return;
    set_cluster_anchoring_config(pcac.data);
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.cluster_anchoring_configuration.name: delete_pending_cluster_anchoring_configuration(*)];

function delete_pending_cluster_anchoring_configuration(proposal) {
    delete pending_cluster_anchoring_configuration @? { proposal };
}

operation propose_cluster_anchoring_configuration(my_pubkey: pubkey, config_data: byte_array) {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_system_provider(my_pubkey);

    val current_config = map&lt;text,gtv&gt;.from_gtv(gtv.from_bytes(cluster_anchoring_config.raw_config));
    require(current_config.size() &gt; 0, "Cluster anchoring is disabled");

    val new_config = map&lt;text, gtv&gt;.from_gtv(gtv.from_bytes(config_data)); // Validate that config is a map
    require(new_config.size() &gt; 0, "Configuration must not be empty");

    val prop = create proposal(op_context.last_block_time, proposal_type.cluster_anchoring_configuration, me, system_p_voter_set());
    create pending_cluster_anchoring_configuration(prop, config_data);
    internal_vote(me, prop, true);
}

query get_cluster_anchoring_configuration_proposal(rowid?) {
    val proposal = get_latest_proposal(rowid, proposal_type.cluster_anchoring_configuration);
    if (proposal == null) return null;
    val pcac = pending_cluster_anchoring_configuration @ { proposal };
    val current_conf = cluster_anchoring_config.raw_config;
    return (
        current_conf = current_conf,
        proposed_conf = pcac.data
    );
}</string>
                            </entry>
                            <entry key="proposal_container/module.rell">
                                <string>module;

import common.*;
import model.*;
import proposal.*;
import .proposal_container_limits.*;</string>
                            </entry>
                            <entry key="proposal_container/proposal_container.rell">
                                <string>entity pending_container {
    key proposal;
    key name;
    cluster;
    deployer: voter_set;
    container_units: integer;
    max_blockchains: integer;
    proposed_by: provider;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.container.name: apply_container(*)];

function apply_container(proposal) {
    val pps = pending_container @? { proposal };
    if (pps == null) return;
    create_container_with_resource_limits(
        pps.proposed_by,
        pps.name,
        pps.cluster,
        pps.deployer,
        pps.container_units,
        pps.max_blockchains
    );
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.container.name: delete_pending_container(*)];

function delete_pending_container(proposal) {
    delete pending_container @? { proposal };
}

// Who can create a new container? Cluster deployers' voter set. (They can also update container limits.)
operation propose_container(my_pubkey: pubkey, cluster_name: text, name, deployer_name: text, description: text = "") {
    // check that provider authority and that it is cluster's deployer
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    val cluster = require_cluster(cluster_name);
    val deployer = require_voter_set(deployer_name);
    require_cluster_governor(cluster, me);
    require_provider_quota(me, provider_quota_type.max_containers);

    val container_units = standard_container_defaults.container_units;
    val max_blockchains = standard_container_defaults.max_blockchains;

    require_cluster_quotas(cluster, container_units);

    val prop = create proposal(op_context.last_block_time, proposal_type.container, me, cluster.governance, description);
    create pending_container(
        prop, name, cluster, deployer, container_units, max_blockchains, me
    );
    internal_vote(me, prop, true);
}

query get_container_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.container);
    if (proposal == null) return null;
    val pcwl = pending_container @ { proposal };
    return (
        container = pcwl.name,
        container_units = pcwl.container_units,
        max_blockchains = pcwl.max_blockchains
    );
}

</string>
                            </entry>
                            <entry key="proposal_container/proposal_container_limits.rell">
                                <string>module;

import ^.*;
import ^^.model.*;

entity pending_container_limits {
    key proposal;
    key container;
    container_units: integer;
    max_blockchains: integer;
}

@extend(is_container_available_for_removal) function(container) = 
if (exists(pending_container_limits @* { container })) 
    "Container %s has pending proposals and can't be deleted. Resolve proposals first".format(container.name) 
else null;

@extend(apply_voting_result_handlers) function() = [proposal_type.container_limits.name: apply_container_limits(*)];

function apply_container_limits(proposal) {
    val pps = pending_container_limits @? { proposal };
    if (pps == null) return;
    update container_resource_limit @ { pps.container, container_resource_limit_type.container_units } ( pps.container_units );
    update container_resource_limit @ { pps.container, container_resource_limit_type.max_blockchains } ( pps.max_blockchains );
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.container_limits.name: delete_pending_container_limits(*)];

function delete_pending_container_limits(proposal) {
    delete pending_container_limits @? { proposal };
}

operation propose_container_limits(my_pubkey: pubkey, container_name: text, limits: map&lt;container_resource_limit_type, integer&gt;, description: text = "") {
    if (limits.contains(container_resource_limit_type.container_units)) {
        val proposed_container_units = limits[container_resource_limit_type.container_units];
        require(proposed_container_units &gt; 0 or proposed_container_units == -1, "Invalid value for container units: %d, must be -1 or greater than 0".format(proposed_container_units));
    }

    val limits_map = get_current_container_resource_limits(container_name);
    limits_map.put_all(limits);

    // check that provider authority and that it is cluster's deployer
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    val container = require_container(container_name);
    require_cluster_governor(container.cluster, me);
    _require_container_units(container, limits_map[container_resource_limit_type.container_units]);
    val prop = create proposal(op_context.last_block_time, proposal_type.container_limits, me, container.cluster.governance, description);
    create pending_container_limits(
        prop,
        container,
        container_units = limits_map[container_resource_limit_type.container_units],
        max_blockchains = limits_map[container_resource_limit_type.max_blockchains]
    );
    internal_vote(me, prop, true);
}

function _require_container_units(container, new_container_units: integer) {
    val current_container_units = get_container_limit_or_default(container, container_resource_limit_type.container_units, standard_container_defaults.container_units);
    val available_container_units = get_available_container_units(container.cluster);
    val required_container_units = new_container_units - current_container_units;
    require(
        required_container_units &lt;= 0 or required_container_units &lt;= available_container_units,
        "Can not propose container limits since container_units is too high for current cluster. Available container_units in cluster are %d but needed is %d".format(available_container_units, required_container_units)
    );
}

query get_container_limits_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.container_limits);
    if (proposal == null) return null;
    val pcl = pending_container_limits @ { proposal };
    return (
        container = pcl.container.name,
        container_units = pcl.container_units,
        max_blockchains = pcl.max_blockchains
    );
}</string>
                            </entry>
                            <entry key="proposal_container/proposal_remove_container.rell">
                                <string>entity pending_remove_container {
    key proposal;
    key container;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.container_remove.name: apply_container_remove(*)];

function apply_container_remove(proposal) {
    val cont = pending_remove_container @? { proposal } .container;
    if (cont == null) return;
    delete container_resource_limit @* { cont };
    delete pending_remove_container @ { proposal };
    delete container @ { cont.name };
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.container_remove.name: delete_pending_remove_container(*)];

function delete_pending_remove_container(proposal) {
    delete pending_remove_container @? { proposal };
}

operation propose_remove_container(my_pubkey: pubkey, name, description: text = "") {
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);
    val cont = require_container(name);
    require_cluster_governor(cont.cluster, me);
    require_container_available_for_removal(cont);

    val prop = create proposal(op_context.last_block_time, proposal_type.container_remove, me, cont.cluster.governance, description);
    create pending_remove_container(prop, cont);
    internal_vote(me, prop, true);
}

query get_container_remove_proposal(rowid?) {
    val proposal = get_latest_proposal(rowid, proposal_type.container_remove);
    if (proposal == null) return null;
    return pending_remove_container @ { proposal } .container.name;
}</string>
                            </entry>
                            <entry key="proposal_provider/module.rell">
                                <string>module;

import proposal.*;
import model.*;</string>
                            </entry>
                            <entry key="proposal_provider/proposal_provider_batch.rell">
                                <string>entity pending_provider_batch {
    key proposal;
    provider_infos: byte_array; // list&lt;provider_info&gt;.to_gtv().to_bytes()
    provider_tier;
    system: boolean;
    active: boolean;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.provider_batch.name: apply_provider_batch(*)];

function apply_provider_batch(proposal) {
    val ppb = pending_provider_batch @? { proposal };
    if (ppb == null) return;
    val providers = list&lt;provider_info&gt;.from_gtv(gtv.from_bytes(ppb.provider_infos));
    for (pi in providers) {
        if (empty(provider @? { pi.pubkey })) {
            register_and_enable_provider(pi, ppb.provider_tier, null, null, ppb.active);
            when {
                ppb.system -&gt; {
                    val provider = provider @ { pi.pubkey };
                    enroll.system(provider);
                    if (not(ppb.active)) {
                        update_provider_state(provider, false, proposal);
                    }
                }
                _is_node_provider(ppb.provider_tier) -&gt; enroll.node(provider @ { pi.pubkey });
            }
        } else {
            log("Warning: provider already exists: " + pi.pubkey);
        }
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.provider_batch.name: delete_pending_provider_batch(*)];

function delete_pending_provider_batch(proposal) {
    delete pending_provider_batch @? { proposal };
}

operation propose_providers(my_pubkey: pubkey, provider_infos: list&lt;provider_info&gt;, tier: provider_tier, system: boolean, active: boolean, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_system_provider(my_pubkey);
    if (system) {
        require(tier == provider_tier.NODE_PROVIDER, "Only NODE_PROVIDER can be marked as system provider");
    }
    require(not(empty(provider_infos)), "Proposed provider key list is empty");

    val providers_map = map&lt;pubkey, provider_info&gt;();
    for (pi in provider_infos) {
        providers_map[pi.pubkey] = pi;
    }
    val providers = providers_map.values();
    for (p in providers) {
        require(empty(provider @? { p.pubkey }), "Provider already exists: " + p.pubkey);
    }

    val already_proposed = set&lt;pubkey&gt;();
    for (ppb in pending_provider_batch @* {}) {
        already_proposed.add_all(
            list&lt;provider_info&gt;.from_gtv(gtv.from_bytes(ppb.provider_infos)) @* {} ( .pubkey )
        );
    }
    for (p in providers) {
        require(not(p.pubkey in already_proposed), "Provider is already proposed: " + p.pubkey);
    }

    val prop = create proposal(op_context.last_block_time, proposal_type.provider_batch, me, system_p_voter_set(), description);
    create pending_provider_batch(prop, providers.to_gtv().to_bytes(), tier, system, active);
    internal_vote(me, prop, true);
}

query get_provider_batch_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.provider_batch);
    if (proposal == null) return null;
    val ppb = pending_provider_batch @ { proposal };
    return (
        provider_infos = list&lt;provider_info&gt;.from_gtv(gtv.from_bytes(ppb.provider_infos)),
        tier = ppb.provider_tier,
        system = ppb.system,
        active = ppb.active
    );
}</string>
                            </entry>
                            <entry key="proposal_provider/proposal_provider_is_system.rell">
                                <string>// Proposed promotion/demotion of provider to/from being system provider
entity pending_provider_is_system {
    key proposal;
    provider;
    system: boolean;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.provider_is_system.name: apply_provider_is_system(*)];

// For promotion and demotion of system providers
function apply_provider_is_system(proposal) {
    val pps = pending_provider_is_system @? { proposal };
    if (pps == null) return;
    // If promotion, update SYSTEM_P voter set
    if (pps.system) {
        enroll.system(pps.provider);
    } else {
        revoke.system(pps.provider);
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.provider_is_system.name: delete_pending_provider_is_system(*)];

function delete_pending_provider_is_system(proposal) {
    delete pending_provider_is_system @? { proposal };
}

operation propose_provider_is_system(my_pubkey: pubkey, provider_pubkey: pubkey, promote: boolean, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_system_provider(my_pubkey);
    val other_prov = require_provider(provider_pubkey);

    require(empty(pending_provider_is_system @* { .provider == other_prov, .system == promote, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
    val prop = create proposal(op_context.last_block_time, proposal_type.provider_is_system, me, system_p_voter_set(), description);
    create pending_provider_is_system(prop, other_prov, .system = promote);
    internal_vote(me, prop, true);
}

query get_system_provider_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.provider_is_system);
    if (proposal == null) return null;
    val pis = pending_provider_is_system @ { proposal };
    return (
        provider = pis.provider.pubkey,
        add = pis.system
    );
}</string>
                            </entry>
                            <entry key="proposal_provider/proposal_provider_quota.rell">
                                <string>entity pending_provider_quota {
    key proposal;
    provider_tier;
    provider_quota_type;
    value: integer;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.provider_quota.name: apply_provider_quota(*)];

function apply_provider_quota(proposal) {
    val ppq = pending_provider_quota @? { proposal };
    if (ppq == null) return;
    update provider_quota @? { ppq.provider_tier, ppq.provider_quota_type } (ppq.value);
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.provider_quota.name: delete_pending_provider_quota(*)];

function delete_pending_provider_quota(proposal) {
    delete pending_provider_quota @? { proposal };
}

operation propose_provider_quota(my_pubkey: pubkey, tier: provider_tier, provider_quota_type, value: integer, description: text = "") {
    val me = require_is_provider_with_rate_limit(my_pubkey);
    require_is_system_provider(my_pubkey);

    // quota value requirements
    when (provider_quota_type) {
        max_actions_per_day -&gt; require(value &gt; 0, "Proposed max_actions_per_day quota value must be &gt; 0: " + value);
        max_nodes -&gt; {
            require(value &gt; 0, "Proposed max_nodes quota value must be &gt; 0: " + value);
        }
        max_containers -&gt; {
            require(value &gt;= -1, "Proposed max_containers quota value must be &gt;= -1: " + value);
            require(tier != provider_tier.COMMUNITY_NODE_PROVIDER, "Proposing max_containers quota is not allowed for COMMUNITY_NODE_PROVIDER");
        }
    }

    val prop = create proposal(op_context.last_block_time, proposal_type.provider_quota, me, system_p_voter_set(), description);
    create pending_provider_quota(prop, tier, provider_quota_type, value);
    internal_vote(me, prop, true);
}

query get_provider_quota_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.provider_quota);
    if (proposal == null) return null;
    val ppq = pending_provider_quota @ { proposal };
    return (
        tier = ppq.provider_tier,
        quota_type = ppq.provider_quota_type,
        value = ppq.value
    );
}</string>
                            </entry>
                            <entry key="proposal_provider/proposal_provider_state.rell">
                                <string>// Proposed enabling/disabling of providers are put here while waiting for enough positive votes.
entity pending_provider_state {
    key proposal;
    provider;
    active: boolean;
}

@extend(apply_voting_result_handlers) function() = [proposal_type.provider_state.name: apply_provider_state(*)];

// For both enabling and disabling of providers:
function apply_provider_state(proposal) {
    val pps = pending_provider_state @? { proposal };
    if (pps == null) return;
    update_provider_state(pps.provider, pps.active, proposal);
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.provider_state.name: delete_pending_provider_state(*)];

function delete_pending_provider_state(proposal) {
    delete pending_provider_state @? { proposal };
}

/*
    The provider with type in line can (+) / can not (-) change the state of the other one in the column:

         | CNP | NP  | SP
    -----|-----|-----|-----
     CNP |  -  |  -  |  -
     NP  |  +  |  -  |  -
     SP  |  +  |  +  |  +
*/
operation propose_provider_state(my_pubkey: pubkey, provider_pubkey: pubkey, active: boolean, description: text = "") {
    val me = require_provider(my_pubkey);
    require_provider_auth_with_rate_limit(me);

    val other_prov = require_provider(provider_pubkey);

    // Only SP and NP can enable/disable providers
    require_node_access(me);

    if (roles.has_node_access(me) and other_prov.tier == provider_tier.COMMUNITY_NODE_PROVIDER) {
        update_provider_state(other_prov, active);
    } else {
        require_system_access(me);
        require(empty(pending_provider_state @* { .provider == other_prov, .active == active, .proposal.state == proposal_state.PENDING } limit 1), "Already proposed");
        val prop = create proposal(op_context.last_block_time, proposal_type.provider_state, me, system_p_voter_set(), description);
        create pending_provider_state(prop, other_prov, .active = active);
        internal_vote(me, prop, true);
    }
}

function update_provider_state(provider, active: boolean, proposal: proposal? = null) {
    provider.active = active;
    if (active == false) {
        update node @* { provider } ( .active = false );

        // cluster nodes
        val cluster_nodes = cluster_node @* { .node.provider == provider } ( .cluster, .node );
        delete cluster_node @* { .node.provider == provider };
        for (cn in cluster_nodes) {
            update_configuration_signers(cn.cluster, cn.node);
        }

        val pending_proposals_with_provider_as_voter = (prop: proposal, vsm: voter_set_member) @* { prop.voter_set == vsm.voter_set, vsm.provider == provider, prop.state == proposal_state.PENDING } ( prop );

        // cluster replica nodes
        delete cluster_replica_node @* { .node.provider == provider };
        // blockchain replica nodes
        delete blockchain_replica_node @* { .node.provider == provider };
        // remove disabled provider from voter_set_member table
        delete voter_set_member @* { .provider == provider };
        // updating node list timestamp
        node_list.last_update = op_context.last_block_time;
        // if provider is last to vote on proposals make sure the proposals are voted on
        for (prop in pending_proposals_with_provider_as_voter) {
            if (proposal != null and prop == proposal) continue;
            try_to_apply_proposal(prop);
        }
    } else { // enable
        // If enabled provider is a system provider, update SYSTEM_P voter set
        if (roles.has_system_access(provider)) {
            create voter_set_member(voter_set @ { voter_sets.system_p }, provider);
        }
    }
}

query get_provider_state_proposal(rowid) {
    val proposal = get_latest_proposal(rowid, proposal_type.provider_state);
    if (proposal == null) return null;
    val pps = pending_provider_state @ { proposal };
    return (
        provider = pps.provider.pubkey,
        provider_name = pps.provider.name,
        active = pps.active
    );
}</string>
                            </entry>
                            <entry key="proposal_voter_set/module.rell">
                                <string>module;

import ^.proposal.*;
import ^.model.*;</string>
                            </entry>
                            <entry key="proposal_voter_set/proposal_voter_set.rell">
                                <string>entity pending_voter_set_update {
    key proposal, voter_set;
}

namespace voter_set_update {
    entity threshold {
        key pending_voter_set_update;
        threshold: integer;
    }

    entity governor {
        key pending_voter_set_update;
        governor: voter_set;
    }

    entity new_member {
        index pending_voter_set_update;
        provider;
    }

    entity remove_member {
        index pending_voter_set_update;
        provider;
    }
}

@extend(apply_voting_result_handlers) function() = [proposal_type.voter_set_update.name: apply_voter_set_update(*)];

function apply_voter_set_update(proposal) {
    val vsp = pending_voter_set_update @? { proposal };
    if (vsp == null) return;
    val threshold = voter_set_update.threshold @? { vsp }.threshold;
    if (threshold != null) vsp.voter_set.threshold = threshold;
    val governor = voter_set_update.governor @? { vsp }.governor;
    if (governor != null) update voter_set_governance @ { .voter_set == vsp.voter_set } (.governor = governor);
    val new_member = voter_set_update.new_member @* { vsp }.provider;
    for (m in new_member) {
        create voter_set_member(vsp.voter_set, m);
    }
    val remove_member = voter_set_update.remove_member @* { vsp }.provider;
    for (m in remove_member) {
        delete voter_set_member @ { vsp.voter_set, m };
    }
}

@extend(delete_proposal_handlers) function(): map&lt;text, (proposal) -&gt; unit&gt; = [proposal_type.voter_set_update.name: delete_pending_voter_set_update(*)];

function delete_pending_voter_set_update(proposal) {
    val p = pending_voter_set_update @? { proposal };
    if (p == null) return;
    delete voter_set_update.threshold @? { p };
    delete voter_set_update.governor  @? { p };
    delete voter_set_update.new_member  @* { p };
    delete voter_set_update.remove_member  @* { p };
    delete p;
}

operation propose_update_voter_set(my_pubkey: pubkey, voter_set_name: text, new_threshold: integer?, new_governor: name?, new_member: list&lt;pubkey&gt;, remove_member: list&lt;pubkey&gt;, description: text = "") {
    val provider = require_is_provider_with_rate_limit(my_pubkey);
    val voter_set = require_voter_set(voter_set_name);
    require(voter_set.name != voter_sets.system_p, "Cannot update system voter set. Update this by proposing system provider role");
    require_voter_set_governor(voter_set, provider);
    require(empty(proposal @* { voter_set, proposal_state.PENDING }), "Cannot have more than one pending proposal involving this voter set.");

    val prop = create proposal(
        op_context.last_block_time,
        proposal_type.voter_set_update,
        provider,
        voter_set_governance @ { voter_set }.governor,
        description
    );
    val update_prop = create pending_voter_set_update(prop, voter_set);
    if (new_threshold != null) {
        require(new_threshold &gt;= -1 and new_threshold &lt;= (voter_set_member @* { voter_set }).size(), 
        "Invalid threshold level, must be in range [-1, voter_set.size()]");
        create voter_set_update.threshold(update_prop, new_threshold);
    }
    if (new_governor != null) {
        val g = require_voter_set(new_governor);
        create voter_set_update.governor(update_prop, g);
    }
    for (m in new_member) {
        val p = require_provider(m);
        require(p.tier == provider_tier.NODE_PROVIDER, "Cannot add a provider that has no voting right to a voter set");
        create voter_set_update.new_member(update_prop, p);
    }
    for (m in remove_member) {
        val p = require_provider(m);
        create voter_set_update.remove_member(update_prop, p);
    }
    internal_vote(provider, prop, true);
}

query get_voter_set_update_proposal(id: integer) {
    val p = proposal @? { rowid(id) };
    if (p == null) return null;
    val pvsu = pending_voter_set_update @? { p };
    if (pvsu == null) return null;
    return (
        voter_set = pvsu.voter_set.name,
        threshold = voter_set_update.threshold @? { pvsu }.threshold,
        governor = voter_set_update.governor @? { pvsu } .governor.name,
        add_member = voter_set_update.new_member @* { pvsu } .provider.pubkey,
        remove_member = voter_set_update.remove_member @* { pvsu } .provider.pubkey
    );
}
</string>
                            </entry>
                            <entry key="roles/module.rell">
                                <string>module;
</string>
                            </entry>
                            <entry key="roles/roles.rell">
                                <string>
import model.*;

namespace roles {

    function has_system_access(provider) = provider.active and provider.system;

    function has_node_access(provider) = provider.active and provider.tier == provider_tier.NODE_PROVIDER;

    function has_deploy_access(provider, container) = provider.active and exists(voter_set_member @? { provider, container.deployer });

}

function require_system_access(provider) = require(roles.has_system_access(provider), "Provider " + provider.pubkey + " must have system priviliges");
function require_node_access(provider) = require(roles.has_node_access(provider), "Provider " + provider.pubkey + " must have permissions to deploy nodes");
function require_deploy_access(provider, container) = require(roles.has_deploy_access(provider, container), "Provider " + provider.pubkey + " must have permissions to deploy in container " + container.name);

namespace enroll {
    function system(provider) {
        provider.active = true;
        provider.system = true;
        node(provider);
        create voter_set_member(provider, system_p_voter_set());
        create cluster_provider(provider, system_cluster());
    }

    function node(provider) {
        provider.tier = provider_tier.NODE_PROVIDER;
    }

}

namespace revoke {
    function system(provider) {
        provider.system = false;
        delete voter_set_member @ { provider, system_container().deployer};
        delete cluster_provider @ { provider, system_cluster() };
    }

    function node(provider) {
        require(roles.has_system_access(provider) != true, "Cannot revoke node access for a system provider. Revoke system access");
        provider.tier = provider_tier.COMMUNITY_NODE_PROVIDER;
        // TODO inactivate all nodes?
    }

}
</string>
                            </entry>
                            <entry key="version.rell">
                                <string>module;

// Increment this everytime a query/op is updated or changed
query api_version(): integer = 13;
</string>
                            </entry>
                        </dict>
                    </entry>
                    <entry key="version">
                        <string>0.12.0</string>
                    </entry>
                </dict>
            </entry>
        </dict>
    </entry>
    <entry key="icmf">
        <dict>
            <entry key="receiver">
                <dict>
                    <entry key="anchoring">
                        <dict>
                            <entry key="topics">
                                <array>
                                    <string>G_configuration_updated</string>
                                    <string>G_configuration_failed</string>
                                </array>
                            </entry>
                        </dict>
                    </entry>
                </dict>
            </entry>
        </dict>
    </entry>
    <entry key="revolt">
        <dict>
            <entry key="fast_revolt_status_timeout">
                <int>2000</int>
            </entry>
        </dict>
    </entry>
    <entry key="signers">
        <array>
            <bytea>037B88FA53A9009A439CC2EB13F0E31D5F364390B3742B7AD091C03216EBF43948</bytea>
        </array>
    </entry>
    <entry key="sync_ext">
        <array>
            <string>net.postchain.d1.icmf.IcmfReceiverSynchronizationInfrastructureExtension</string>
        </array>
    </entry>
</dict>
